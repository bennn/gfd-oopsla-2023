\newcommand{\numgtp}{16}
\newcommand{\boundaryMB}{536} % 536244 kb
\newcommand{\statisticalMB}{4645} % 4645788 kb
\newcommand{\runtimeMB}{44}

%% -----------------------------------------------------------------------------
Running the rational-programmer experiment requires a large pool of
computing resources.  To begin with, it demands reliable measurements for
all complete migration lattices. Then, it needs to use the measurements to
compute the outcome of navigating the
lattices following each strategy starting from every performance-debugging
scenario. This section starts with a description of the measurement
process (section~\ref{subsec:experiment}). The remaining two subsections
(sections~\ref{subsec:qx} and~\ref{s:hh}) explain how the outcome of the
experiment answers the two research questions from the preceding
section.

%% -----------------------------------------------------------------------------
\subsection{Experiment} \label{subsec:experiment} \label{sec:data}

The experiment uses the v7.0 release of the GTP Benchmarks
with small restructurings to help the boundary profiler attribute costs
correctly.
The restructuring does not affect the run-time behavior of the programs.
See \ifappendix{\cref{s:adaptor-rewrite}}{the supplementary material}
for details.
Also, the experiment omits four of the twenty-one benchmarks:
\bmname{zordoz}, because it currently cannot run all deep/shallow/untyped
configurations due to a known issue;\footnote{
\url{https://github.com/bennn/gtp-benchmarks/issues/46}}
\bmname{gregor},\bmname{quadT}, and \bmname{quadU} because each has over 1.5
million configurations, which makes it infeasible to measure their complete
migration lattices; and \bmname{sieve} because it has just two modules.

\paragraph{Measurements} 

The ground-truth measurements consist of running times, \boundary{} profiler output,
and \statistical{} profiler output.  Collecting this data required three basic steps
for each configuration of the \numgtp{} benchmarks:
\begin{enumerate}

\item Run the configuration once, ignoring the result, to warm up the JIT.  Run
  eight more times to collect {cpu time}s reported by the Racket \code{time} function.

\item Install the boundary profiler and run it once, collecting output.

\item Install the statistical profiler and run it once, collecting output.

\end{enumerate}

\begin{table}[t]
  \caption{Datasets, their origin, and server details}
  \Description{Datasets, their origin, and server details}
  \label{t:data-collection}

  \begin{tabular}{llll}
    Dataset           & Server & Racket & Typed Racket \\\midrule
    dungeon           & \machinename{c220g2} & \stdrkt{} &  \commitname{29ea3c10}{29ea3c105e0bd60b88c1fd195b54fa716863f690} \\
    morsecode         & \machinename{m510}   & same & \commitname{700506ca}{700506ca01393f211229101c47d8420f6d535de9} (cherry pick) \\
 %% quadT runtime  & \machinename{m510}   & same & same \\
    other runtime     & \machinename{c220g1} & same & default \\
    other profile      & \machinename{m510}   & same & default
  \end{tabular}

  \bigskip

  \begin{tabular}{llrrr}
    %% multi-cpu, multi-core machines .. but we didn't use that, right?
    Server & Site & CPU Speed & RAM & Disk \\\midrule
    \machinename{c220g1} & Wisconsin & 2.4GHz & 128GB & 480GB SSD \\
    \machinename{c220g2} & Wisconsin & 2.6GHz & 160GB & 480GB SSD \\
    \machinename{m510}   & Utah      & 2.0GHz &  64GB & 256GB SSD
  \end{tabular}

\end{table}

%% $11 * \totalnumconfigs{} = \totalnummeasurements{}$

The large scale of the experiment complicates the management of this vast
measurement collection.
The 1,277,694 measurements come from 116,154
configurations.
\Cref{t:data-collection} (top) shows the division of work across
servers from CloudLab~\cite{cloudlab}.
Each server ran a sequence of measurement tasks and nothing else;
no other users ran jobs during the experiment's reservation time.
\Cref{t:data-collection} (bottom) lists the specifications of
the machines used.
In total, the results take up 5GB of disk space.
Measurements began in July 2022 and finished in April 2023.

For all but two benchmarks, the measurements used a recent version
of Racket (v8.6.0.2, on Chez~\cite{racket-chez}) and the Typed Racket that ships with it.
The exceptions are \bmname{dungeon} and \bmname{morsecode},
which pulled in updates to Typed Racket that significantly affected
their performance.\footnote{\url{https://github.com/racket/typed-racket/pull/1282}, \url{https://github.com/racket/typed-racket/pull/1316}}
Fixing these issues was not necessary for the rational programmer experiment
per se, but makes the outcome more relevant to current versions of Racket.

%% https://github.com/racket/typed-racket/pull/1316

\begin{table}[t]
  \caption{How many of the $3^N$ configurations have any overhead to begin with?}
  \label{t:baseline-trouble}
  \begin{tabular}[t]{l@{\qquad}l}
    \begin{tabular}[t]{lrr}
      Benchmark           & $3^N$ & \% Scenario \\\midrule
      \bmname{morsecode}  &    81 & \pct{82.72} \\
      \bmname{forth}      &    81 & \pct{93.83} \\
      \ycell{\bmname{fsm}}        &    \ycell{81} & \ycell{\pct{76.54}} \\
      \bmname{fsmoo}      &    81 & \pct{83.95} \\
      \bmname{mbta}       &    81 & \pct{88.89} \\
      \bmname{zombie}     &    81 & \pct{91.36} \\
      \bmname{dungeon}    &   243 & \pct{99.59} \\
      \bmname{jpeg}       &   243 & \pct{94.65} \\
    \end{tabular}
    &
    \begin{tabular}[t]{lrr}
      Benchmark           & $3^N$ & \% Scenario \\\midrule
      \ycell{\bmname{lnm}}        &   \ycell{729} & \ycell{\pct{40.47}} \\
      \bmname{suffixtree} &   729 & \pct{98.49} \\
      \bmname{kcfa}       &  2,187 & \pct{92.87} \\
      \bmname{snake}      &  6,561 & \pct{99.97} \\
      \bmname{take5}      &  6,561 & \pct{99.95} \\
      \bmname{acquire}    & 19,683 & \pct{99.23} \\
      \bmname{tetris}     & 19,683 & \pct{95.47} \\
      \bmname{synth}      & 59,049 & \pct{99.99}
    \end{tabular}
  \end{tabular}
\end{table}

\paragraph{Basic Observations}

The measurements confirm that the GTP benchmarks are suitable for
the rational programmer experiment~(\cref{t:baseline-trouble}).
With $T = 1$ as the goal of migration, all but two benchmarks
have plenty of performance-debugging scenarios.
Going by configurations rather than benchmarks, over \pct{80} of all
configurations are interesting starting points for the experiment.

%% -----------------------------------------------------------------------------
\begin{figure}[ht]
  \includegraphics[width=\columnwidth]{data/strategy-overall-feasible.pdf}
  \Description{How many of the 114,428 scenarios does each strategy succeed in, for six notions of success.}
  \caption{How many of the 114,428 scenarios does each strategy succeed in, for six notions of success.}
  \label{f:strategy-overall}
\end{figure}

\subsection{Answering $Q_X$} \label{subsec:qx}

\Cref{f:strategy-overall} presents the results of navigating with all strategies
from the preceding section starting from all scenarios. It answers
research question $Q_X$~(\cref{subsec:questions}).

Each stacked bar in the ``skyline'' of \cref{f:strategy-overall} corresponds to
a different strategy. Concretely, it reports the success
rate of the strategy for increasingly loose notions of success for $T = 1$.  The
lowest, widest part of each bar represents the percentage of scenarios where the
strategy is strictly successful. The next three levels represent $1$-loose,
$2$-loose, and $3$-loose success percentages.  The striped spire is for
$N$-loose successes.  And finally, the antenna corresponds to a
strict success but for $T = 3$.

The strategies come with a wide range of success rates: 
\begin{itemize}
  \item
    \emph{Optimistic} navigation performs well when guided by the \emph{boundary} profiler,
    finding strict success in almost \pct{40} of all scenarios. 
    With a $2$-loose relaxation, success rises to above \pct{50}.
    The results are far worse, however, with \emph{statistical (total)} or \emph{statistical (self)}
    profiling, both of which rarely succeed.

  \item
    \emph{Cost-aware optimistic} is almost as successful as optimistic when driven
    by \featkw{} and equally successful with \emph{statistical (total)}
    and \emph{statistical (self)}.

  \item
    \emph{Conservative} navigation is unsuccessful no matter what profiler it uses.

  \item
    \emph{Cost-aware conservative} is unsuccessful as well.
    Even with $N$-loose relaxation, it succeeds in very few scenarios~(\pct{2}).

  \item
    \emph{Configuration-aware optimistic} navigation with
    \featkw{} succeeds in approximately \pct{36} of all
    configurations under strict and just over \pct{50} with $3$-loose.
    With \emph{statistical (total)} and \emph{statistical (self)}
    profiling,
    the success rate drops to \pct{10} even for $N$-loose.

  \item
    \emph{Null} navigation succeeds for roughly \pct{5} of all scenarios.
    Though low, this success rate is better than the conservative strategies.
    Allowing for 1,2,3-loose success improves the rate by small
    increments.
    With $N$-loose, the success rate jumps to nearly \pct{40}.
    (These results are the average success rates across three trials. The standard deviations
    for each number were very low, under $\pct{0.10}$.)

  \item
    \emph{Toggling} achieves strict success a bit more often than random, for
    roughly \pct{6} of all scenarios.
    The other notions of success do not apply to toggling because it stops after one step.
\end{itemize}

\paragraph{Antenna: 3x Strict Success} \label{s:antenna}

There are two possible reasons for the poor success rate of the conservative
strategies.
One is that they are entirely unproductive; they lead to worse performance.
The other possibility is that they do improve performance but are unable
to achieve a $T$x overhead because there are no such configurations that
consist mostly of shallow types.
This second possibility is likely due to the current implementation of shallow
types~\cite{g-deep-shallow}, which rarely achieves a speedup relative to untyped
code.

To distinguish between these two possibilities,
figure~\ref{f:strategy-overall} includes the antennas that
reports strict successes when $T = 3$ is acceptable.  The
number 3x is the classic, arbitrary Takikawa constant for ``acceptable'' gradual typing
overhead~\cite{vss-popl-2017,bbst-oopsla-2017}.  Changing to 2x or 4x does not
significantly change the outcome.

For \emph{conservative} and \emph{cost-aware conservative}, allowing a 3x
overhead improves results across the profilers. The strategies succeed in an
additional \pct{10} of scenarios.  The optimistic strategies with \statkw{}
improve in a similar way for 3x success.  Optimistic with \featkw{} does
not improve, and neither does the null strategy.  Toggling
improves tremendously for 3x success, in line with prior work on shallow, which
reports a median worst-case overhead of 4.2x on the GTP
Benchmarks~\cite{g-deep-shallow}.  Evidently, about \pct{45} of configurations can
reach a 3x overhead simply by switching to shallow types.

\paragraph{Omitting Hopeless Scenarios} From the perspective of type
migration, some scenarios are hopeless. No matter what recommendation a strategy
makes for the boundary-by-boundary addition of types to these scenarios,
the performance cannot improve to the $T=1$ goal.

\Cref{t:blackhole} lists the number of scenarios in each benchmark and the
percentage of hopeful ones. A low percentage in the third column (labeled ``\%
Hopeful'') of this table means that the experiment is stacked against any rational
programmer.  For several benchmarks, this is indeed the case.  Worst of all are
\bmname{mbta}, \bmname{dungeon}, and \bmname{take5}, which have zero hopeful
scenarios.  Three others are only marginally better: \bmname{forth},
\bmname{zombie}, and \bmname{acquire}.

\begin{table}[ht]
  \caption{How many scenarios can possibly reach 1x without removing types?}
  \label{t:blackhole}
  \begin{tabular}[t]{l@{\qquad}l}
    \begin{tabular}[t]{lrr}
      Benchmark                &  \# Scenario &  \% Hopeful \\\midrule
      \bmname{morsecode}       &           67 &    \pct{100.00} \\
      \bmname{forth}           &           76 &     \pct{36.84} \\
      \bmname{fsm}             &           62 &    \pct{100.00} \\
      \bmname{fsmoo}           &           68 &    \pct{100.00} \\
      \rcell{\bmname{mbta}}    &   \rcell{72} & \rcell{\pct{0.00}} \\
      \bmname{zombie}          &           74 &     \pct{35.14} \\
      \rcell{\bmname{dungeon}} &  \rcell{242} & \rcell{\pct{0.00}} \\
      \bmname{jpeg}            &          230 &    \pct{100.00}
    \end{tabular}
    &
    \begin{tabular}[t]{lrr}
      Benchmark                &   \# Scenario &  \% Hopeful \\\midrule
      \bmname{lnm}             &           295 &    \pct{100.00} \\
      \bmname{suffixtree}      &           718 &    \pct{100.00} \\
      \bmname{kcfa}            &         2,031 &    \pct{100.00} \\
      \bmname{snake}           &         6,559 &    \pct{100.00} \\
      \rcell{\bmname{take5}}   & \rcell{6,558} & \rcell{\pct{0.00}} \\
      \bmname{acquire}         &        19,532 &      \pct{5.45} \\
      \bmname{tetris}          &        18,791 &    \pct{100.00} \\
      \bmname{synth}           &        59,046 &    \pct{100.00}
    \end{tabular}
  \end{tabular}
\end{table}

\begin{figure}[ht]
  \includegraphics[width=\columnwidth]{data/strategy-overall-hopeful.pdf}
  \caption{How many of the 88,992 hopeful scenarios does each strategy succeed in, for six notions of success.}
  \Description{How many of the 88,992 hopeful scenarios does each strategy succeed in, for six notions of success.}
  \label{f:strategy-hope}
\end{figure}

\Cref{f:strategy-hope} therefore revisits the measurements reported in
\cref{f:strategy-overall}, focusing on hopeful scenarios only.  If there is no
migration path from a scenario to a configuration with a tolerable overhead, the
scenario is excluded as hopeless.  As before, the results for \emph{random
boundary} are the average across three runs.  The standard deviation is slightly
higher than before ($<\pct{0.12}$).

For the optimistic strategies, the results are much better.
With boundary profiling, they succeed in an additional \pct{10} of
scenarios under either strict or $N$-loose success.  
With statistical profiling, the optimistic strategies
improve slightly.

Unfortunately, the conservative strategies perform no better than for all
scenarios.
In fact, the antennae
in~\cref{f:strategy-hope} are shorter than the antennae
in~\cref{f:strategy-overall}.  This means that conservative strategies
succeeded in the strict 3x sense in a small number of hopeless scenarios that
do not appear in~\cref{f:strategy-hope}.


\begin{figure}[ht]
  \includegraphics[width=0.9\columnwidth]{data/head-to-head.pdf}
  \Description{Boundary optimistic vs. the rest, strict success: losses (red bars) and wins (green bars) on all scenarios.}
  \caption{Boundary optimistic vs. the rest, strict success: losses (red bars) and wins (green bars) on all scenarios.}
  \label{f:head-to-head}
\end{figure}

%% -----------------------------------------------------------------------------
\subsection{Answering $Q_{X/Y}$} \label{subsec:hh} \label{s:hh}

The preceding subsection hints at how the strategies compare to each other.
\emph{Optimistic-boundary} navigation is the most likely to succeed on an
arbitrary configuration.  \emph{Cost-aware} and \emph{configuration-aware} using
the optimistic strategy are close behind.  The conservative strategies are least
likely to find a successful configuration no matter what profiler they use.
Boundary profiling is always more successful than statistical profiling.

However,
an unanswered question is whether there are particular cases in which the other
strategies succeed and optimistic-boundary fails.
\Cref{f:head-to-head} thus compares the \emph{optimistic-boundary} strategy to all
others, and it thus answers research question $Q_{X/Y}$.  The $y$-axis reports
percentages of scenarios.  The $x$-axis lists all strategies including
optimistic-boundary (on the left).  For each strategy, there are at most two
vertical bars.  A red bar appears when the other strategy succeeds on
configurations where optimistic-boundary fails.  A green bar appears for the
reverse situation, where optimistic-boundary succeeds but the other fails.  Ties
do not count,  hence the red and green bars do not combine to \pct{100}.

The tiny red bars and tall green bars give a negative answer to
the question of whether optimistic boundary performs worse in
certain cases.
Other strategies rarely succeed where optimistic-boundary fails.

