\newcommand{\numgtp}{16}
\newcommand{\gtpurl}{\url{https://docs.racket-lang.org/gtp-benchmarks/index.html}}
\newcommand{\boundaryMB}{536} % 536244 kb
\newcommand{\statisticalMB}{4645} % 4645788 kb
\newcommand{\runtimeMB}{44}

This section presents the results of a rational programmer
experiment that compares 17 strategies on programs from
the GTP benchmark suite~\cite{gtp-benchmarks}.


\subsection{Benchmarks}

The GTP benchmarks are a collection of small to mid-sized Typed Racket programs
that support a full lattice of mixed-typed interactions.
Since the benchmarks originate from useful scripts
and exercise a variety of types at module boundaries~\cite{gtnffvf-jfp-2019},\footnote{\gtpurl{}}
they are an appropriate testbed for comparing navigation strategies.
Configurations with high overhead due to deep types should benefit from
feature-specific profiling, while configurations that suffer from shallow
types may benefit more from the statistical profiler.

The experiment uses the v7.0 release of the GTP Benchmarks with small modifications
to support feature-specific profiling.
Version 7.0 is outdated, but was the latest version when we began collecting
data in Fall 2022.
The modifications add static information so that the profiler can peek through
\emph{adaptor modules} in specific benchmarks.
They do not change the run-time behavior of the code.
In total, nine benchmarks are affected~(\cref{s:adaptor-rewrite}).
Source code for the original benchmarks and our modified ones will be available
in the artifact for this paper.

We omit four of the 21 benchmarks:
\bmname{zordoz} because it currently cannot run all deep/shallow/untyped configurations
due to a known issue;\footnote{\url{https://github.com/bennn/gtp-benchmarks/issues/46}}
\bmname{gregor},\bmname{quadT}, and \bmname{quadU} because we lack the resources
to run a full experiment (each has over 1.5 million configurations);
and \bmname{sieve} because it is very small, with only four configurations.
\textbf{NOTE TO OOPSLA REVIEWERS}:
we have collected performance data for \bmname{quadT} and hope to
collect profile results in the coming weeks.


\subsection{Profiling Tools}

Racket ships with tools for statistical and feature-specific profiling.
The feature-specific profiler is able to isolate the cost of contracts.
Since deep gradual types compile to contracts, this default contract
mode is suitable for the experiment.

We use these two default tools with small modifications to make the output
easier to analyze.
For the statistical profiler, we change the default output format to
JSON rather than a text table~(see~\cref{sec:seascape}).
For the feature-specific profiler, we group the contracts by boundary and
sort the groups in decreasing order.
Thus the most expensive boundary appears at the top rather than the single
most expensive contract.
The modified code is will be in our artifact.


\subsection{Data Collection}

Executing a rational programmer requires two kinds of ground-truth data:
running times and profiler results.

FILL collected between July 2022 and today (ongoing).
Over 4GB of data, combined.
%% \boundaryMB + \statisticalMB + \runtimeMB
quadT runtime between August 2022 and October 2022, since then, unable to get a huge
block of machines for the profile and boundary data.




FILL explain "u" setup, appendix?


% https://www.cloudlab.us/

Our experiments call for three kinds of data for every configuration across the benchmarks:
\begin{enumerate}
  \item Running time
  \item Boundary-profile output
  \item Statistical-profile output
\end{enumerate}

To collect one running time, we used nine runs of the configuration:
one throwaway run to warm up the Racket JIT and eight other runs to compute an average.
To collect boundary and statistical output, we ran each configuration once.
Thus we took $11 * \totalnumconfigs{} = \totalnummeasurements{}$ measurements in total.

We collected all the data on CloudLab~[CITE].
For running times, we used the Wisconsin cluster c220g1 
FILL: exception for morsecode.

FILL: exact racket/tr code available on zenodo

FILL: footnote, quadT in the works; report current status

boundary from another cluster, same racket
exceptions: dungeon, morsecode
profile, ditto

Tried two modes for statistical profiler: total time and self time.
Comparable, but total succeeds in a greater number of configurations.
There do exist configs where total fails and self succeeds.
Focus on total for most of paper (TODO where?)


\begin{table}[t]
  \caption{Datasets}
  \label{t:data-collection}

  \begin{tabular}{llll}
    Dataset           & Server & Racket & Typed Racket \\\midrule
    dungeon           & \machinename{c220g2} & \stdrkt{} &  \commitname{29ea3c10}{29ea3c105e0bd60b88c1fd195b54fa716863f690} \\
    morsecode         & \machinename{m510}   & same & \commitname{700506ca}{700506ca01393f211229101c47d8420f6d535de9} (cherry pick) \\
 %% quadT runtime  & \machinename{m510}   & same & same \\
    other runtime     & \machinename{c220g1} & same & default \\
    profilers         & \machinename{m510}   & same & same
  \end{tabular}

  \bigskip

  \begin{tabular}{llrrr}
    %% multi-cpu, multi-core machines .. but we didn't use that, right?
    Server & Site & CPU Speed & RAM & Disk \\\midrule
    \machinename{c220g1} & Wisconsin & 2.4GHz & 128GB & 480GB SSD \\
    \machinename{c220g2} & Wisconsin & 2.6GHz & 160GB & 480GB SSD \\
    \machinename{m510}   & Utah      & 2.0GHz &  64GB & 256GB SSD
  \end{tabular}
\end{table}




For our experiments, we consider every configuration as a starting point.
From the starting point, the goal is to reach a fast configuration without
removing types from a module.
(In other words, the \emph{target} is the set of typed modules in the start
configuration.)
A fast configuration runs at least as quickly as the untyped code.
Using the established terminology~\cite{vss-popl-2017,bbst-oopsla-2017},
we instatiate the Takikawa constant to 1x ($T=1$).

A very simple way to try improving performance is to toggle between
Deep and Shallow.
\citet{g-deep-shallow} provides justification.
Any configuration can reach 0, 1, or 2 other configurations by
toggling, that is, by changing all its typed modules to Deep or
changing all to Shallow.
(Only the untyped configuration can reach 0 others.)

First question: for how many configurations does $T=1$ present a debugging challenge?
More precisely, how many cannot reach $T=1$ by toggling?

(The untyped configuration can trivially reach $T=1$.
The fully-typed configuration can usually reach $T=1$, unless there are heavy
boundaries to untyped contextual modules.)

\Cref{t:baseline-trouble} shows that many benchmarks need help,
over 100k configurations in total.
The median \% that need help is 82\%.
Only \bmname{fsm} and \bmname{lnm} have low percentages: 8\% and 44\%.
FILL say more

\begin{table}[t]
  \caption{How many of the $3^N$ configurations have any overhead to begin with?}
  \label{t:baseline-trouble}
  \begin{tabular}[t]{l@{\qquad}l}
    \begin{tabular}[t]{lrr}
      Benchmark           & $3^N$ & \% Slow \\\midrule
      \bmname{morsecode}  &    81 & 82.72\% \\
      \bmname{forth}      &    81 & 93.83\% \\
      \ycell{\bmname{fsm}}        &    \ycell{81} & \ycell{76.54\%} \\
      \bmname{fsmoo}      &    81 & 83.95\% \\
      \bmname{mbta}       &    81 & 88.89\% \\
      \bmname{zombie}     &    81 & 91.36\% \\
      \bmname{dungeon}    &   243 & 99.59\% \\
      \bmname{jpeg}       &   243 & 94.65\% \\
    \end{tabular}
    &
    \begin{tabular}[t]{lrr}
      Benchmark           & $3^N$ & \% Slow \\\midrule
      \ycell{\bmname{lnm}}        &   \ycell{729} & \ycell{40.47\%} \\
      \bmname{suffixtree} &   729 & 98.49\% \\
      \bmname{kcfa}       &  2187 & 92.87\% \\
      \bmname{snake}      &  6561 & 99.97\% \\
      \bmname{take5}      &  6561 & 99.95\% \\
      \bmname{acquire}    & 19683 & 99.23\% \\
      \bmname{tetris}     & 19683 & 95.47\% \\
      \bmname{synth}      & 59049 & 99.99\%
    \end{tabular}
  \end{tabular}
\end{table}

\begin{figure}[t]
  \includegraphics[width=\columnwidth]{data/strategy-overall-feasible.pdf}
  \caption{Strategy head-to-head, mono only, 114,428 scenarios. Profiles on left. Agnostics on right. RandomB is average of 3 runs, max stddev <0.1}
  \label{f:strategy-overall}
\end{figure}

\begin{table}[t]
  \caption{How many of the $3^N$ configurations cannot reach 1x without removing types?}
  \label{t:blackhole}
  \begin{tabular}[t]{l@{\qquad}l}
    \begin{tabular}[t]{lrr}
Benchmark           & $3^N$ & \% Hopeless \\\midrule
\bmname{morsecode}  &    81 &         0\% \\
\bmname{forth}      &    81 &      59.26\% \\
\bmname{fsm}        &    81 &         0\% \\
\bmname{fsmoo}      &    81 &         0\% \\
      \rcell{\bmname{mbta}}       &    \rcell{81} &      \rcell{88.89\%} \\
\bmname{zombie}     &    81 &      59.26\% \\
      \rcell{\bmname{dungeon}}    &   \rcell{243} &      \rcell{99.59\%} \\
\bmname{jpeg}       &   243 &         0\%
    \end{tabular}
    &
    \begin{tabular}[t]{lrr}
Benchmark           & $3^N$ & \% Hopeless \\\midrule
\bmname{lnm}        &   729 &         0\% \\
\bmname{suffixtree} &   729 &         0\% \\
\bmname{kcfa}       &  2187 &         0\% \\
\bmname{snake}      &  6561 &         0\% \\
      \rcell{\bmname{take5}}      &  \rcell{6561} &      \rcell{99.95\%} \\
\bmname{acquire}    & 19683 &      93.83\% \\
\bmname{tetris}     & 19683 &         0\% \\
\bmname{synth}      & 59049 &         0\%
    \end{tabular}
  \end{tabular}
\end{table}

\begin{figure}[t]
  \includegraphics[width=0.8\columnwidth]{data/strategy-overall-hopeful.pdf}
  \caption{Hopeful only, 88,992 scenarios. RandomB is average of 3 runs, max stddev <0.12}
  \label{f:strategy-hope}
\end{figure}

\begin{figure}[t]
  \includegraphics[width=0.9\columnwidth]{data/head-to-head.pdf}
  \caption{Opt vs everyone, all scenarios}
  \label{f:head-to-head}
\end{figure}

\clearpage

