\newcommand{\numgtp}{16}
\newcommand{\boundaryMB}{536} % 536244 kb
\newcommand{\statisticalMB}{4645} % 4645788 kb
\newcommand{\runtimeMB}{44}

%% -----------------------------------------------------------------------------
Running the rational-programmer experiment requires a large pool of computing
resources.  To begin with, it demands reliable measurements for all complete
migration lattices. Then, it needs to use the measurements to compute the
outcome of applying the various modes of the rational programmer to the
now-identifiable performance-debugging scenarios. This section starts with a
description of the measurement process (section~\ref{subsec:experiment}). The
remaining two subsections (sections~\ref{subsec:qx} and~\ref{s:hh}) explain how
the outcome of the experiment answers the two research questions from the
preceding section.

%% -----------------------------------------------------------------------------
\subsection{Experiment} \label{subsec:experiment} \label{sec:data}

The experiment uses the v7.0 release of the GTP Benchmarks. The programs are
modified so that the boundary profiler can measure the cost of boundary crossing
in some benchmarks. See appendix for details.  The
modifications do not affect the run-time behavior of the programs.  Also the
collection used for the experiment omits four of the twenty-one benchmarks:
\bmname{zordoz}, because it currently cannot run all deep/shallow/untyped
configurations due to a known issue;\footnote{
\url{https://github.com/bennn/gtp-benchmarks/issues/46}}
\bmname{gregor},\bmname{quadT}, and \bmname{quadU} because each has over 1.5
million configurations, which makes it infeasible to measure their complete
migration lattices; and \bmname{sieve} because it has just two modules.

\paragraph{Measurements} 

The ground-truth measurements consist of running times, boundary-profile output,
and statistical-profile output.  Collecting this data required three basic steps
for each configuration of the \numgtp{} benchmarks:
\begin{enumerate}

\item Run the configuration once, ignoring the result, to warm up the JIT.  Run
    eight more times measuring performance.  In particular, the recorded {cpu
    time}s is from the Racket \code{time} function.

\item Install and run the boundary profiler and run it once, collecting output.

\item Install and run the statistical profiler and run it once, collecting
output.

\end{enumerate}

\begin{table}[ht]
  \caption{Datasets, their origin, and server details}
  \label{t:data-collection}

  \begin{tabular}{llrrr}
    %% multi-cpu, multi-core machines .. but we didn't use that, right?
    Server & Site & CPU Speed & RAM & Disk \\\midrule
    \machinename{c220g1} & Wisconsin & 2.4GHz & 128GB & 480GB SSD \\
    \machinename{c220g2} & Wisconsin & 2.6GHz & 160GB & 480GB SSD \\
    \machinename{m510}   & Utah      & 2.0GHz &  64GB & 256GB SSD
  \end{tabular}

  \bigskip

  \begin{tabular}{llll}
    Dataset           & Server & Racket & Typed Racket \\\midrule
    dungeon           & \machinename{c220g2} & \stdrkt{} &  \commitname{29ea3c10}{29ea3c105e0bd60b88c1fd195b54fa716863f690} \\
    morsecode         & \machinename{m510}   & same & \commitname{700506ca}{700506ca01393f211229101c47d8420f6d535de9} (cherry pick) \\
 %% quadT runtime  & \machinename{m510}   & same & same \\
    other runtime     & \machinename{c220g1} & same & default \\
    other profile      & \machinename{m510}   & same & same
  \end{tabular}

\end{table}

%% $11 * \totalnumconfigs{} = \totalnummeasurements{}$

The large scale of the experiment complicates the management of this vast
measurement collection.  The 1,277,694 measurements come from 116,154
configurations.  The measurement processes ran on CloudLab~\cite{cloudlab}
servers using a recent
%% https://github.com/racket/typed-racket/pull/1316
version of Racket.
The specifications of these machines are reported in~\cref{t:data-collection} (top).
\Cref{t:data-collection} (bottom) matches datasets to clusters.
The processes utilized one core per server in an effort to obtain reliable performance
results.
In total, the results take up 5GB of disk space.
Measurements began in July 2022 and finished only in April 2023.

% Both the \bmname{dungeon} and \bmname{morsecode} benchmarks took a different
% path and used only one machine type: \machinename{c220g2} and
% \machinename{m510}, respectively.
% This is because we collected their data much later than the other benchmarks,
% after discovering and fixing two issues in Typed Racket that significantly
% affected their performance.\footnote{\url{https://github.com/racket/typed-racket/pull/1282}, \url{https://github.com/racket/typed-racket/pull/1316}}
% For \bmname{dungeon}, we used a newer Typed Racket commit.
% For \bmname{morsecode}, we cherry-picked one small commit onto the default Typed Racket
% for Racket v8.6.0.2 (to be available in our artifact).
% Fixing these issues \emph{was not necessary} for the rational programmer experiment.
% The only reason for re-running was to stay current with major changes to Typed Racket.

\begin{table}[ht]
  \caption{How many of the $3^N$ configurations have any overhead to begin with?}
  \label{t:baseline-trouble}
  \begin{tabular}[t]{l@{\qquad}l}
    \begin{tabular}[t]{lrr}
      Benchmark           & $3^N$ & \% Scenario \\\midrule
      \bmname{morsecode}  &    81 & 82.72\% \\
      \bmname{forth}      &    81 & 93.83\% \\
      \ycell{\bmname{fsm}}        &    \ycell{81} & \ycell{76.54\%} \\
      \bmname{fsmoo}      &    81 & 83.95\% \\
      \bmname{mbta}       &    81 & 88.89\% \\
      \bmname{zombie}     &    81 & 91.36\% \\
      \bmname{dungeon}    &   243 & 99.59\% \\
      \bmname{jpeg}       &   243 & 94.65\% \\
    \end{tabular}
    &
    \begin{tabular}[t]{lrr}
      Benchmark           & $3^N$ & \% Scenario \\\midrule
      \ycell{\bmname{lnm}}        &   \ycell{729} & \ycell{40.47\%} \\
      \bmname{suffixtree} &   729 & 98.49\% \\
      \bmname{kcfa}       &  2,187 & 92.87\% \\
      \bmname{snake}      &  6,561 & 99.97\% \\
      \bmname{take5}      &  6,561 & 99.95\% \\
      \bmname{acquire}    & 19,683 & 99.23\% \\
      \bmname{tetris}     & 19,683 & 95.47\% \\
      \bmname{synth}      & 59,049 & 99.99\%
    \end{tabular}
  \end{tabular}
\end{table}

\paragraph{Basic Observations}

Collecting the measurements confirms that the GTP benchmark suite is useful for
the rational-programmer experiment. \Cref{t:baseline-trouble} tabulates the
landscape of benchmarks.  All but two have plenty of scenarios; over 80\% of all
configurations have some overhead relative to untyped.  Navigating to a
successful configuration is therefore a challenge overall.

%% -----------------------------------------------------------------------------
\begin{figure}[ht]
  \includegraphics[width=\columnwidth]{data/strategy-overall-feasible.pdf}
  \caption{How many of the 114,428 scenarios does each strategy succeed in, for six notions of success.}
  \label{f:strategy-overall}
\end{figure}

\subsection{Answering $Q_X$} \label{subsec:qx}

\Cref{f:strategy-overall} presents the results of running all modes of the
rational programmer from the preceding section on all scenarios. It answers
research question $Q_X$. 

Each stacked bar in the ``skyline'' of \cref{f:strategy-overall} corresponds to
a different mode of the rational programmer. Concretely, it reports the success
rate of the mode for increasingly-loose notions of success for $T = 1$.  The
lowest, widest part of each bar represents the percentage of scenarios where the
mode is strictly successful. The next three levels represent $1$-loose,
$2$-loose, and $3$-loose success percentages.  The striped spire is for
$N$-loose successes.  And finally, the antenna uses the even weaker notion of
strict success for $T = 3$.

The modes come with a wide range of success rates: 
\begin{itemize}
  \item
    \emph{Optimistic} navigation performs well when guided by the \emph{boundary} profiler,
    finding strict success in almost 40\% of all scenarios. 
    With a $2$-loose relaxation, success rises to above 50\%.
    The results are far worse, however, with \emph{statistical (total)} or \emph{statistical (self)}
    profiles, both of which perform comparably.

  \item
    \emph{Cost-aware optimistic} is almost as successful as optimistic when driven
    by \emph{boundary} profiles and equally successful with \emph{statistical (total)}
    and \emph{statistical (self)}.

  \item
    \emph{Conservative} navigation is unsuccessful no matter what profiler it uses.

  \item
    \emph{Cost-aware conservative} is unsuccessful as well.
    Even with $N$-loose relaxation, it is successful in only a handful of scenarios (2\%).

  \item
    \emph{Configuration-aware optimistic} navigation with
    \emph{boundary} profiles succeeds in approximately 36\% of all
    configurations under strict and just over 50\% with $3$-loose.
    With \emph{statistical (total)} and \emph{statistical (self)} profiles,
    the success rate drops to 10\% even for $N$-loose.

  \item
    \emph{Null} navigation succeeds for 5\% of all scenarios.
    This is a low number, but much better than the conservative strategies.
    Allowing for 1,2,3-loose success improves the rate incrementally and with an
    $N$-loose notion of success, it goes up to nearly 40\%.
    (These results are the average success rates across three trials. The standard deviations
    for each number were low, under $0.10\%$.)

  \item
    \emph{Toggling} achieves strict success a bit more often than random, for
    roughly 6\% of all scenarios.
    The other notions of success do not apply to toggling because it can step to at most one configuration.
\end{itemize}

\paragraph{Antenna: 3x Strict Success} \label{s:antenna}

There are two possible reasons for the poor success rate of the conservative
strategies.
One is that they are entirely unproductive; they lead to worse performance.
The other possibility is that they do improve performance but are unable
to achieve a $T$x overhead because there are no such configurations that
consist mostly of shallow types.
This second possibility is likely due to the current implementation of shallow
types~\cite{g-deep-shallow}, which almost always adds some overhead.

To distinguish between these two possibilities, figure~\ref{f:strategy-overall}
reports the success rates with antennas. These thin lines atop each ``building''
represent scenarios for which a strict success when $T = 3$ is acceptable.  The
number 3x is the classic Takikawa constant for ``acceptable'' gradual typing
overhead~\cite{vss-popl-2017,bbst-oopsla-2017}.  Changing to 2x or 4x does not
significantly change the outcome.

For \emph{conservative} and \emph{cost-aware conservative}, allowing a 3x
overhead improves results across the profilers. The modes succeed on an
additional 10\% of scenarios.  The optimistic modes with statistical profiles
improve in a similar way for 3x success.  Optimistic with boundary profiles does
not improve, and neither does the null mode.  Toggling
improves tremendously for 3x success, in line with prior work on shallow, which
reports a median worst-case overhead of 4.2x on the GTP
Benchmarks~\cite{g-deep-shallow}.  Evidently, about 45\% of configurations can
reach a 3x overhead by switching to shallow types.

\begin{table}[ht]
  \caption{How many scenarios can possibly reach 1x without removing types?}
  \label{t:blackhole}
  \begin{tabular}[t]{l@{\qquad}l}
    \begin{tabular}[t]{lrr}
      Benchmark                &  \# Scenario &  \% Hopeful \\\midrule
      \bmname{morsecode}       &           67 &    100.00\% \\
      \bmname{forth}           &           76 &     36.84\% \\
      \bmname{fsm}             &           62 &    100.00\% \\
      \bmname{fsmoo}           &           68 &    100.00\% \\
      \rcell{\bmname{mbta}}    &   \rcell{72} & \rcell{0.00\%} \\
      \bmname{zombie}          &           74 &     35.14\% \\
      \rcell{\bmname{dungeon}} &  \rcell{242} & \rcell{0.00\%} \\
      \bmname{jpeg}            &          230 &    100.00\%
    \end{tabular}
    &
    \begin{tabular}[t]{lrr}
      Benchmark                &   \# Scenario &  \% Hopeful \\\midrule
      \bmname{lnm}             &           295 &    100.00\% \\
      \bmname{suffixtree}      &           718 &    100.00\% \\
      \bmname{kcfa}            &         2,031 &    100.00\% \\
      \bmname{snake}           &         6,559 &    100.00\% \\
      \rcell{\bmname{take5}}   & \rcell{6,558} & \rcell{0.00\%} \\
      \bmname{acquire}         &        19,532 &      5.45\% \\
      \bmname{tetris}          &        18,791 &    100.00\% \\
      \bmname{synth}           &        59,046 &    100.00\%
    \end{tabular}
  \end{tabular}
\end{table}

\begin{figure}[ht]
  \includegraphics[width=\columnwidth]{data/strategy-overall-hopeful.pdf}
  \caption{How many of the 88,992 hopeful scenarios does each strategy succeed in, for six notions of success.}
  \label{f:strategy-hope}
\end{figure}

\paragraph{Omitting Hopeless Scenarios} From the perspective of type migration,
some scenarios are hopeless. No matter how the modes of the rational programmer
add types to these scenarios, the performance cannot improve to the $T=1$ goal.

\Cref{t:blackhole} lists the number of scenarios in each benchmark and the
percentage of hopeful ones. A low percentage in the third column (labeled ``\%
Hopeful'') of this table means that the experiment is stacked against the rational
programmer.  For several benchmarks, this is indeed the case.  Worst of all are
\bmname{mbta}, \bmname{dungeon}, and \bmname{take5}, which have zero hopeful
scenarios.  Three others are only marginally better: \bmname{forth},
\bmname{zombie}, and \bmname{acquire}.

\Cref{f:strategy-hope} therefore revisits the measurements reported in
\cref{f:strategy-overall}, focusing on hopeful scenarios only.  If there is no
migration path from a scenario to a configuration with a tolerable overhead, the
scenario is excluded as hopeless.  As before, the results for \emph{random
boundary} are the average across three runs.  The standard deviation is slightly
higher than before ($<0.12\%$).

For the optimistic modes, the results are much better.  They succeed on an
additional 10\% of scenarios under strict success with the \emph{optimistic,
boundary} strategy, and the $N$-loose results improve along the same lines.
With statistical profiles, the optimistic strategies improve slightly.

Unfortunately the conservative modes perform no better.  They improve on few
hopeful scenarios according to the notion of $N$-loose success.  Strict 3x
successes are rare as well.  Indeed the antennae in~\cref{f:strategy-hope}
are shorter than the antennae in~\cref{f:strategy-overall}.  This means that
conservative succeeded in the 3x sense on a number of hopeless configurations;
such configurations cannot reach a 1x point, but they can reach a 3x point.


\begin{figure}[ht]
  \includegraphics[width=0.9\columnwidth]{data/head-to-head.pdf}
  \caption{Boundary optimistic vs. the rest, strict success: losses (red bars) and wins (green bars) on all scenarios.}
  \label{f:head-to-head}
\end{figure}

%% -----------------------------------------------------------------------------
\subsection{Answering $Q_{X/Y}$} \label{subsec:hh} \label{s:hh}

The preceding subsection hints at how the strategies compare to each other.
\emph{Optimistic-boundary} navigation is the most likely to succeed on an
arbitrary configuration.  \emph{Cost-aware} and \emph{configuration-aware} using
the optimistic strategy are close behind.  The conservative strategies are least
likely to find a successful configuration no matter what profiler they use.
Boundary profiling is always more successful than statistical profiling.

However,
an unanswered question is whether there are particular cases in which the other
strategies succeed and optimistic-boundary fails.
\Cref{f:head-to-head} thus compares the \emph{optimistic-boundary} strategy to all
others, and it thus answers research question $Q_{X/Y}$.  The $y$-axis reports
percentages of scenarios.  The $x$-axis lists all strategies including
optimistic-boundary (on the left).  For each strategy, there are at most two
vertical bars.  A red bar appears when the other strategy succeeds on
configurations where optimistic-boundary fails.  A green bar appears for the
reverse situation, where optimistic-boundary succeeds but the other fails.  Ties
do not count.  Hence, the red and green bars do not combine to 100\%.

The figure also answers the question concerning cases where the
boundary-optimistic strategy fails but some other strategy succeeds.
Specifically, the tiny red bars and tall green bars give a negative answer to
this question.  Other strategies rarely succeed where optimistic-boundary fails.

