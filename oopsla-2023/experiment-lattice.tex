%% -----------------------------------------------------------------------------

Gradual type migration is an open and challenging problem for realistic
programs~\cite{rch:in-out-infer-gt, km:ts-type-evo,
mp:gt-decidable, ccew:gt-migrate, gc:gt-infer,
cagg-solver-based-migration,clps-popl-2020,js-infer,ruby-static-infer,unif-infer,
msi:gt-infer-hm,dyn-infer-ruby,profile-guided-typing,jstrace,gen-ts-decl,
lambdanet,nl2ptype,learn-types-big-data,ml-ts}. For
any untped component, a migrating programmer has to choose among several
practical type annotations and often among an infinite number of theoretical
ones. But, to make a rational-programmer experiment computationally feasible, it
is necessary to avoid this dimension.

Fortunately, the GTP benchmarks come with well-chosen type annotations for all
their components.  Hence, the migration lattices can be pre-constructed for all
benchmark programs~\citep{tfgnvf-popl-2016}.  It is thus possible to start a
rational programmer mode from any performance-debugging scenario in this
lattice---a program with intolerable performance---and make it use the known
types of the components to chart a path through the program's migration lattice.

A rational-programmer mode thus combines a strategy \strategyvar{} with a
function that picks points from the migration lattice. That is, the mode
$\mode{\strategyvar{}}$ is a partial function from a program $\program{}_0$ to a
program $\program{}_n$. To get from $\program{}_0$ to $\program{}_n$,
$\mode{\strategyvar{}}$ iterates \strategyvar{} on its input and applies its
recommendations to obtain successively.  In other words, $\mode{\strategyvar{}}$
constructs a \emph{migration path}, a sequence of programs ${\program{}_0},
\ldots, {\program{}_n}$ from a migration lattice. If \strategyvar{} cannot make
a recommendation at any point in this lattice, $\mode{\strategyvar{}}$ does not
produce a result. The following definitions translate these points into rigorous
language. 

\paragraph{The Migration Lattice.}  All programs $\program{}_i$ are nodes in the
\emph{migration lattice} \lattice{\program{}_u} where ${\program{}_u}$, is like
${\program{}_i}$ but all its components are untyped. The bottom element of
\lattice{\program{}_u} is ${\program{}_u}$; its top elements are
${\program{}_u}$'s fully typed versions $\program{}_t$ (with some combination of
deep and shallow). In between these extreme points are all the remaining
\emph{configurations} of $\program{}_u$. The $3^N$ configurations of
\lattice{\program{}_u} are ordered:$\ordered{\program{}_i}{\program{}_j}$ iff
$\program{}_j$ has at least one component that is untyped in
$\program{}_j$. Hence the lattice is organized in \emph{levels} of incomparable
configurations, each of which lacks types for the same components but differs
from others in the choice of enforcement regime for one (or more) of its typed
components.  $\orderqed{\program{}_i}{\program{}_j}$ denotes that either
$\program{}_i$ and $\program{}_j$ are at the same level or $\program{}_i$ is at
some level below $\program{}_j$.

A migration path corresponds to a collection of configurations $\program{}_i$,
$0 \leq i < n$, such that $\orderqed{\program{}_i}{\program{}_{i+1}}$. In fact,
either $\program{}_i$ and $\program{}_{i+1}$ are at the same level or they are
at two neighboring ones.  This statement is the formal equivalent to the
description from the preceding section that strategies either add types to a
single previously untyped component or toggle the type enforcement of existing
typed components.\footnote{None of the strategies modifies a boundary where both
side are untyped. Such boundaries are invisible to the feature-specific
profiler, and the strategies that use the statistical one explicitly filter them
out. Ditto for the profiler-agnostic ones.}  In other words, a migration path is
a weakly ascending chain in
\lattice{\program{}_u}.

%% MF: I think this is obvious. We can discuss if you think not. 

% This last observation is key for the implementation of the rational-programmer
% experiment. If for each $\program{}_u$ in the experiment, one of its fully type
% versions $\program{}_t$ is also available, then the construction of
% \lattice{\program{}_u} is automatic, and as a result, so are the modifications
% that the strategies produce. Therefore, given implementations of the strategies
% and a collection of seed programs with both untyped and fully typed versions,
% the rational-programmer experiment reduces to a fully automated push-button
% process that asks all modes of the rational programmer to construct a migration
% path starting at the same configurations of
% \lattice{\program{}_u}, and compares their successes. 

\paragraph{Performance-debugging scenarios and success criteria.} Completing the
formal description of the experiments demands answers to two more questions.

The first concerns the selection of the starting points for the modes of the
rational programmer, i.e., the \emph{performance-debugging scenarios}.  The
answer is that every configuration $\program$ that exhibits performance
degradation compared to $\program{}_u$ above a certain threshold is an
interesting starting point for a rational-programmer exploration.

\begin{quote} \em

Given a migration lattice \lattice{\program{}_u},
a \emph{performance-debugging scenario} is a configuration $\program$ in \lattice{\program{}_u} 
iff
\slowdown{\program}{\program{}_u} > \takikawa{},\\
 where \slowdown{\program}{\program{}_u} is the ratio of the performance of \program{} over the performance of $\program{}_u$,\\ 
 and $\takikawa{}$ is a constant that signifies the maximum acceptable performance degradation.
\end{quote}

The second question is about differentiating successful from failing migrations.
In this case, there are two answers. Strictly speaking, performance should
always improve, otherwise the programmer may not wish to invest any more effort
into migration.  In the worst case, performance might stay the same for a few
migration steps, before it becomes tolerable.

\begin{quote} \em

A migration path ${\program{}_0} \ldots {\program{}_n}$ in a lattice \lattice{\program{}_u}
is \emph{strictly successful}
iff
\begin{enumerate}
  \item $\program{}_0$ is a performance-debugging scenario,
  \item $\slowdown{\program{}_n}{\program{}_u} \leq \takikawa{}$, and 
  \item for all $0 \leq i < n$, $\slowdown{\program{}_i}{\program{}_{i+1}} \leq 1$.
 \end{enumerate} 
\end{quote}
The construction of a strictly successful migration path requires a strategy
that suggests modifications that monotonically improve the performance of  a
program en route to making it performant.

The alternative to strict success is to represent a programmer who tolerates
occasional setbacks. Accepting that a migration path may come with $k$ setbacks,
a $k$-loose success relaxes the requirement for monotonicity $k$ times.

\begin{quote} \em

Given $k \leq n$, a migration path ${\program{}_0} \ldots {\program{}_n}$ in a
lattice \lattice{\program{}_u} is \emph{$k$-loosely successful}
iff 
\begin{enumerate}
  \item  $\program{}_0$ is a performance-debugging scenario,
  \item $\slowdown{\program{}_n}{\program{}_u} \leq \takikawa{}$  
  \item there exists a subsequence of the path 
    ${\program{}^\prime_0} \ldots {\program{}^\prime_m}$ such that
     $m + k = n$ and
      for all $0 \leq j < m$,
      $\slowdown{\program{}^\prime_j}{\program{}^\prime_{j+1}} \leq 1$.
      (This subsequence is not necessarily a path in the lattice.)
  \end{enumerate} 
\end{quote}
The construction of a $k$-loose successful migration path allows a strategy to
temporarily stir migration towards worse performance. The constant $k$ is an
upper on the number of such missteps.

An infinitely patient programmer may wish to relax this constraint even more.

\begin{quote} \em
A migration path is $N$-loosely successful iff for any $k, n$, $k \leq n$ it is
\emph{$k$-loosely successful}. 
\end{quote}
