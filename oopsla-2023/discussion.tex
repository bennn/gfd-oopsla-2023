
The working programmer does not know the complete migration lattice. 

Programmers should aim at approximating the performance of the completely
untyped configuration.


For a program with a handful of components, a programmer should randomly
add types or toggle all existing types until the performance is tolerable.
Other than in those cases, shallow type enforcement does not seem to
offer any advantages. 

In case, a programmer thinks that a large mixed-typed program exhibits
intolerable performance, it is time to reach for the boundary profiler.
Furthermore, when the boundary profiler is able to identify a particular
as a cause of the bad performance, the programmer is best served by
converting both sides of the boundary to use deep types.  This should be
done by toggling existing shallow types to deep, if possible; otherwise,
adding deep types to the untyped module.  In support of this argument, the
programmer can safely ignore assessing any characterestic of the program
or the migration step; the blindly optimistic approach is as good or
better than approaches that require additional effort. 

If a programmer uses the boundary profiler with an optimistic approach,
and the result is a performance degradation, then it is unlikely that any
of strategies presented here will help debug the performance problem. 


%% -----------------------------------------------------------------------------
\subsection{Threats to Validity}


Threats to validity:

internal
————
representative benchmarks: black holes, what happens in the wild 


profiler limitations, especially the boundary one — see class-based
programs

migration steps: (1) typing one module at a time 
                 (2) splitting large modules is perhaps better

strategies: missing strategies


external
—————
one language and its toolset 

real programmers may not have access to libraries etc

real programmers may not have the patience to act as rational programmers
but may have ``hunches'' that pay off in realistic scenarios 


