%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This work touches a range of existing strands of research. At
the object-level, the main motivation for this paper is prior research on
the performance issues of sound gradual typing.
Two significant
sources of inspiration are research on gradual type migration and
profiling techniques.  At the meta-level, this work builds on and extends
prior results on the rational programmer method.

\paragraph{Performance of Gradual Types} 

\citet{gtnffvf-jfp-2019} demonstrate the grim performance problems of deep
gradual types.
Adding deep types to just a few components can make a program prohibitively
slow, and the slowdown may remain until nearly every component has types.
This observation sets the stage for the work in this paper.
Furthermore, the experimental approach of that work provides the
$3^N$ migration lattices that
are key for the rational programmer experiment herein, and one of the
strategies (toggling).

Earlier work observed the negative implications of deep types
and proposed mitigation techniques.
Roughly, the techniques fall in two groups. The first
group proposes the design of alternative run-time checking strategies that
aim to control the time and space cost of checks while providing
some type guarantees (e.g.~\citep{sgt-esop-2009,rmhn-ecoop-2019,glfd-pj-2022,lgmvpk-pj-2023,g-popl-2015,svctg-esop-2015,rat-oopsla-2017,sfrbcsb-popl-2014,rsfbv-popl-2015,coersion-passing-style}).
One notable strategy is transient, which was developed for Reticulated
Python~\cite{vksb-dls-2014,vss-popl-2017,vsc-dls-2019,v-thesis-2019},
adapted to Grace and JIT-compiled to greatly reduce
costs~\cite{rmhn-ecoop-2019,grmhn-vmil-2019}
and later characterized as providing \emph{shallow} types that offer
type soundness but not complete monitoring~\cite{gfd-oopsla-2019}.
\citet{type-untyped} provide a detailed analysis and comparison of the
overall checking strategy landscape.

The second group of mitigations reduce the time and space required
by deep types without changing their
semantics~\cite{htf-hosc-2010,stw-jfp-2021,stw-pldi-2015,collapsible,corpse-reviver,
kas-pldi-2019, pycket,bbst-oopsla-2017}.
This is a promising line of work.
In the context of Pycket, for example, the navigation problem is easier
than Typed Racket because many more configurations run efficiently.
But, pathologies still remain.
Navigation techniques are an important complement to performance improvements.

Several language designs take a hybrid approach to gradual types
so that programmers can avoid the costs of deep checks.
Thorn and StrongScript use a mixture of
\emph{optional} and \emph{concrete} types~\citep{wzlov-popl-2010,rzv-ecoop-2015}.
Optional types never introduce run-time checks (same as TypeScript~\cite{bat-ecoop-2014} or Flow~\cite{cvgrl-oopsla-2017}).
Concrete types perform cheap nominal type checks but limit the values that components
can exchange; for example, typed code that expects an array of numbers cannot accept
untyped arrays.
Dart 2 explores a similar combination of optional and
concrete.\footnote{\url{https://dart.dev/language/type-system\#runtime-checks}}
Nom~\cite{mt-oopsla-2017,mt-oopsla-2021} and SafeTS~\cite{rsfbv-popl-2015} independently
proposed concrete types as a path to efficient gradual types.
Static Python combines concrete and shallow types to ease the limitations
of concrete~\citep{lgmvpk-pj-2023}.
Pyret uses deep checks for fixed-size data and shallow checks for recursive
data and functions.\footnote{\url{http://www.pyret.org}}
Typed Racket recently added shallow and optional types as alternatives to its deep
semantics~\cite{g-deep-shallow}.

\paragraph{Gradual Type Migration}
Research on gradual type migration can be split in three broad directions:
static techniques~\cite{rch:in-out-infer-gt, km:ts-type-evo,
mp:gt-decidable, ccew:gt-migrate, gc:gt-infer,
cagg-solver-based-migration,clps-popl-2020,js-infer,ruby-static-infer,unif-infer};
dynamic
techniques~\cite{msi:gt-infer-hm, dyn-infer-ruby, profile-guided-typing, gen-ts-decl, jstrace},
and techniques based on machine learning
(ML)~\cite{lambdanet,nl2ptype,learn-types-big-data,ml-ts}. The dynamic
and ML-based techniques exhibit the most scalable results so far as they
can produce accurate annotations for a range of components in the wild,
such as JavaScript libraries.
However, as \citet{ml-ts} note, the problem is far from solved.
% ``automatically predicting type annotations is a challenging task and much
% work remains to be done.''
Moreover, no existing technique takes into account feedback from profilers to
guide migration.
One opportunity for future work is to combine the profiling strategies in this
paper with migration techniques in the context of automatic or
human-in-the-loop tools.

\citet{ccw-icfp-2018} combine type migration with a static cost semantics
to predict the relative performance of configurations in a migration lattice.
This approach is compelling because it avoids the need to run mixed-typed
programs; whereas our work measures $3^N$ configurations, they measure
only the untyped configuration and still identify a fastest point.
It would be interesting to extend their migration and static-cost tools to
a full-featured type system (at least with universal and union types),
and to test whether the approach can find \emph{satisficing} configurations
as well as the fastest one.
%% TODO do we have satisficing configs througout the lattice?


\paragraph{Performance Tuning with Profilers} Profilers are the de facto
tool that developers use to understand the causes of performance bugs. 
Tools such as GNU gprof~\cite{gprof} established statistical (sampling) 
profilers that collect caller-function execution time data, and paved the
way for the development of statistical profilers in many languages,
including Racket.

In addition to Racket's statistical profiler, the experiment in this
paper also uses Racket's feature-specific
profiler~\cite{staaf-feature-prf}. A
feature-specific profiler
groups execution time based on (instances) of language features of
developers' choosing rather than by function calls.  For instance, the
boundary profiler that the experiment of this paper employs aggregates
the cost of contracts in a program by the boundary that introduces
them.

There are two prior works that have used profiler feedback to understand
the source of the high cost of gradual types.
First,~\citet{astavf-feature-prf} show that the Racket feature-specific profiler can detect
hot boundaries in programs that use deep types, i.e., it can
identify boundaries that are the origin of costly deep checks.
Second, \citet{grmhn-vmil-2019} use end-to-end timing information
to identify costly shallow types.
We conjecture that using a statistical profile could lead to similar
conclusions with fewer runs of the program.

Unlike this paper, prior work on profilers and gradual typing does not
examine how to translate profiler feedback to developer actions.
The suggested repair is to remove expensive types.
In general, most profiling tools do not make recommendations to
programmers. The Zoom profiler~\cite{zoom} was one
notable exception, though its recommendations were phrased in
terms of assembly language rather than high-level code.

A number of profiling and performance analysis tools provide
alternative views. Two recent tools include
a vertical profiler~\cite{vertical-profiler} and a
concept-based profiler~\cite{java-profile-concepts}.
Both target Java programs.
A vertical profiler splits performance data along different
levels of abstraction, such as VM cost, syscall cost, and application
cost. A concept-based profiler groups performance costs based on
user-defined portions of a codebase called concepts~\cite{concepts}.
It would be interesting to study alternative profiling and performance
analysis techniques in future rational-programmer experiments.


\paragraph{The Rational Programmer}

 \citet{lksfd-popl-2020,lgfd-icfp-2021} propose the rational programmer as
 an empirical method for evaluating the role of blame in debugging coding
 mistakes with software contracts and gradual types. However, the ideas
 behind the rational programmer go beyond debugging such mistakes. In
 essence, the rational programmer is a general methodological framework
 for the systematic investigation of the pragmatics of programming
 languages and tools. That is, it can quantify the value of the various
 aspects of a language or a tool in the context of a specific task. In
 that sense, prior work focuses on a single context: debugging
 coding mistakes.

 This paper shows how the rational programmer applies
 to experiment design in another context: performance tuning and debugging of performance
 problem. Hence, it shares the language feature it studies, gradual
 typing, with prior work. But it looks at a different aspect
 of its pragmatics. As a result, besides contributing to the understanding
 of the value of gradual types, it also provides evidence for the
 generality of the rational programmer method itself.


