%% -----------------------------------------------------------------------------

Sound migratory typing promises a safe and smooth refactoring path from an
untyped code base to a typed one~\cite{tf-dls-2006, tfffgksst-snapl-2017}. It
realizes the safe part with the compilation of types to run-time checks that
guarantee type-level integrity of each mixed-typed program configuration.
Unfortunately, these run-time checks impose a large performance
overhead~\cite{gtnffvf-jfp-2019}, making the path anything but smooth.
This problem is particularly stringent for deep run-time
checks~\cite{tf-dls-2006, st-sfp-2006}, but it also applies to shallow run-time
checking~\cite{gm-pepm-2018}.
While improvements to deep and shallow can reduce the severity of the
problem, in particular JIT technology for
shallow~\cite{rmhn-ecoop-2019,vsc-dls-2019},
the core issue remains---some configurations need more expensive checks than
others.

\citet{g-thesis-2020,g-deep-shallow} presents evidence that deep and shallow
checks actually come with complementary strengths and weaknesses. Deep checks
impose a steep cost at boundaries between typed and untyped code, yet as
the addition of types eliminates such boundaries, they
enable type-driven optimizations that can offset some of the
cost~\cite{s-northeastern-2015}---and sometimes all of it.
By contrast, shallow checks impose a low cost at every potential interaction
with untyped code, yet as the addition of types increases the number of
checks, they result in an increasing accumulative cost.
Hence, Greenman argues that developers should, in
principle, be able to mix and match deep and shallow checking to get the
best-possible type checking benefits with a tolerable performance penalty.
Initial empirical data is promising: with the right mixture of checks,
it is possible to avoid order-of-magnitude slowdowns that come from either
deep or shallow checks alone.
Finding a ``right'' mixture, however, presents a challenge because there
are many possibilities to choose from.
Whereas in a purely deep (or shallow) checking scheme, developers have
$2^N$ configurations to choose from, with deep and shallow combined
there are $3^N$ possibilities because each of the $N$ components in
the program can be untyped, deep-typed, or shallow-typed.

The large search space raises the following question:
\begin{quote} \em
 How to navigate the $3^N$ migration lattice of a code base from a
  configuration with unacceptable performance to one with acceptable
  performance?
\end{quote}
Since this is a performance problem, a plausible answer is to use profiling tools.
%% ... readymade ... off-the-cuff ... glib
But, this conventional response merely refines the above question in two
ways, namely:
\begin{itemize} \item[] \begin{itemize}\em
\item How to use feedback from various profiling tools to choose a next step; and
\item Whether a sequence of choices leads to a configuration with
  acceptable performance.
\end{itemize} \end{itemize}

Such questions call for an empirical investigation.
A user study is a viable way forward, but recruiting a large number
of people to debug problems in unfamiliar code is costly and introduces
confounding factors.
Until recently, however, there was no other way to proceed systematically.
Instead, this paper reports on the results of a \emph{rational programmer}
experiment~\cite{lksfd-popl-2020,lgfd-icfp-2021,lgfd-icfp-2023}.
The rational programmer method employs algorithmic abstractions (\emph{strategies})
that are inspired by methods that actual humans can follow and that reify a
falsifiable hypothesis about one way of using profiling tools and
interpreting their feedback.
Because the strategies are algorithms, it is straightforward to apply them
to thousands of debugging scenarios and test whether they improve performance.
In sum, the rational programmer experiment enables a systematic comparison
of different ways that human developers\footnote{To distinguish
between humans and the rational programmer, the 
paper exclusively uses ``developer'' for human coders.} might interpret profiler feedback.
The winning strategies merit further study, while the losing ones can be
set aside.

In short, this paper makes three contributions:
\begin{itemize}

\item At the technical level, the rational programmer experiment presents
  the most comprehensive and systematic examination of type migration
    paths to date.    As such it goes far beyond ~\citet{g-deep-shallow}'s 
    prior work.  The experiment evaluates 17 different strategies for
    interpreting profiling output on  more than one hundred thousand scenarios using the GTP
    benchmarks~\cite{g-rep-2023}. It yields
     5GB of performance and profiling data, which
    is available on
    Zenodo~\cite{gdf-artifact-2023}.
  
\item At the object level, the results of the rational programmer
  experiment provide guidance to developers about how to best use feedback
    from profilers during type migration. Specifically, 
    migrating to deep types the piece of code with the most costly
    boundary with other parts of the code base
    outperforms all other  strategies on the scenarios of
    the experiment. This result is a \emph{surprise} given~\citet{g-deep-shallow}'s
    preliminary data, which implies that shallow types, or the combination of shallow and deep
    types, may contribute better options.

     \item[]\begin{itemize}
      \item
         Hence, the results also inform language designers about
         performance dividends from investing in  the combination.
    \end{itemize}


\item At the meta level, this application of the rational programmer method to
 the performance problems of type migration provides evidence for its versatility
 as an instrument for studying language pragmatics.

\end{itemize}
The remainder of the paper is organized as follows.  \Cref{sec:seascape}
uses an example to explain the problem in concrete terms. \Cref{sec:ideas}
introduces the rational programmer method and shows how its use can systematically
evaluate the effectiveness of a performance-debugging strategy.
\Cref{sec:experiment} translates these ideas to a
large-scale quantitative experiment.
\Cref{sec:results} presents the data from the experiment, which
explores scenarios at a module-level granularity in Typed Racket.
\Cref{sec:discussion} extracts lessons for developers and researchers.
\Cref{sec:related} places this work in the context of prior research.
\Cref{sec:conclusion} puts this work in perspective with respect to future
research.
