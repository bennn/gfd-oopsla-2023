%% -----------------------------------------------------------------------------

Over the years, developers have created many large systems in untyped languages.
In the meantime, language implementors have created gradually typed siblings of
these languages.  Since developers tend to enjoy the benefits of type-based IDE
support and a blessing from the type checker, they are likely to add new
components in the typed sibling language. Alternatively, when a developer is
confronted with debugging an untyped component, it takes a large mental effort
to reconstruct the informal types of fields, functions, and methods, and to make
this effort pay off, it is best to turn the informal types into formal
annotations. In either case, the result is a mixed-typed software system with
boundaries between typed and untyped components.

In a sound gradual language, these boundaries impose a performance penalty.  Languages can
enforce sound types with deep or shallow checks. A deep check means that types are
translated to higher-order contracts~\cite{ff-icfp-2002,tf-dls-2006,st-sfp-2006}.
Higher-order contracts impose many kinds of performance penalties: they check all
compound values when they cross a boundary; they wrap all higher-order values with
proxies to delay checks; and such proxies also raise memory consumption. By
contrast, a shallow check means that types are enforced only with tag-level
assertions and only inside of typed components~\cite{vss-popl-2017,
vksb-dls-2014}. Each check is inexpensive, but the more type annotations a
programmer adds, the more run-time checks the compiler inserts for typed
components. As a result, the performance penalty can become prohibitive in
either case. If so, the developer faces a performance-debugging scenario.

To make this concrete, consider the \bmname{fsm} program from the GTP benchmark
suite~\cite{gtnffvf-jfp-2019}. The program is the creation of \citet{fsm},
economists interested in simulating an economy of agents with deterministic
strategies. Figure~\ref{f:fsm-code:a} shows the outline of the four-module
program: \code{auto} implements state machines; \code{pop} coordinates among
machines; \code{main} drives the simulation and permits users to set a number of
simulation parameters; and \code{util} provides helper functions.  Focusing on
just the modules of this program suffices because in Typed Racket, the migration
granularity is a module.

The variant of \bmname{fsm} on the left of figure~\ref{f:fsm-code:a} is untyped.
If a developer adds deep types to the \code{main} module, performance is
significantly degraded. The mixed-typed variant runs almost three times
($3x$) slower than the untyped one.  Switching to shallow types does not remedy
the situation. 

%% 3x not terrible compared to prior work [CITE popl], but still bad.
%% Collapsible helps fsm but not in this particular config & not in fsmoo.

At this point, the question is how to recover the performance of the untyped
variant. The first option is to roll back the addition of types, but developers
prefer typed code and dislike undoing the effort of adding types. The second one
is to add (deep or shallow) types to a random module connected to \code{main}---following a
``hunch'' like programmers sometimes do---but doing so can easily make things
worse. For example, if the choice were the \code{auto} module with shallow
types, then performance would degrade further (a 9x slowdown, to be
precise). Finally, adding deep types to every module is the option that is almost
always guaranteed to fix the situation, and in this context, it would produce a
performance improvement over the untyped variant.  However, such a choice
represents a heavy migration effort, which a programmer who simply
wishes to fix \code{main} and deploy again may be reluctant to invest.

%% -----------------------------------------------------------------------------
%% fsm next steps:
%% 1100 => 2.87x
%% 2100 => 9.04x
%% 2200 => 9.06x
%% 1200 => 2.88x

\begin{figure}[htb]\centering
  %% profiler output: data/example-output-fsm/*

  \begin{subfigure}[t]{\columnwidth}\centering
    \begin{tikzpicture}
      \node (1) [draw=black!80] {\cmod{util}};
      \node (1c) [draw=black!80,left=of 1.west,xshift=9mm] {\cmod{pop}};
      \node (1b) [draw=black!80,left=of 1c.west,xshift=9mm] {\cmod{main}};
      \node (1a) [draw=black!80,left=of 1b.west,xshift=9mm] {\cmod{auto}};
%      \node (0) [above of=1a,yshift=-2mm] {Program: \bmname{fsm}};

      \node (2) [above of=1,yshift=1mm,xshift=2cm,draw=black!80] {\cmod{auto}};
      \node (2a) [draw=black!80,line width=0.6mm,right=of 2.east,xshift=-9mm] {\cmod{main}};
      \node (2tgt) [below of=2a,yshift=7mm,xshift=1mm] {};
      \node (2b) [draw=black!80,right=of 2a.east,xshift=-9mm] {\cmod{pop}};
      \node (2c) [draw=black!80,right=of 2b.east,xshift=-9mm] {\cmod{util}};
      \node (22) [right=of 2c.east,xshift=-10mm] {\textbf{2.9x} slowdown};
%      \node (24) [above of = 22,yshift=-6mm] {Deep types};

      \node (3) [below of=2,yshift=-6mm,draw=black!80] {\cmod{auto}};
      \node (3a) [draw=black!80,line width=0.6mm,right=of 3.east,xshift=-9mm] {\cmod{main}};
      \node (3b) [draw=black!80,right=of 3a.east,xshift=-9mm] {\cmod{pop}};
      \node (3c) [draw=black!80,right=of 3b.east,xshift=-9mm] {\cmod{util}};
      \node (33) [right=of 3c.east,xshift=-10mm] {\textbf{2.8x} slowdown};
%      \node (34) [above of = 33,yshift=-6mm] {Shallow types};

      \node (dlbl) [above of=2a,yshift=-5mm] {deep};
      \node (slbl) [below of=3a,yshift=5mm] {shallow};

      \draw[-{Stealth[length=2mm,width=2mm]}] (1b.north) -- (2tgt);
      \draw[-{Stealth[length=2mm,width=2mm]}] (2a.south) -- (3a.north);

    \end{tikzpicture}

    \caption{Adding deep or shallow types to one \bmname{fsm} module degrades performance} \label{f:fsm-code:a}
  \end{subfigure}

  \bigskip

  \begin{subfigure}[t]{0.53\columnwidth}
%%-------------------------------------------------
%% [1] 1192(100.0%)   0(0.0%)  body of ....
%%                              body of ....
%%-------------------------------------------------
%%                              profile-thunk [5]
%% [6] 1192(100.0%)   0(0.0%)  ??? profile-lib
%%                              body of "main" [7]
%%                              t [8]
%%                              body of ....
%%-------------------------------------------------

    \footnotesize
    \begin{boxedverbatim}
  Total cpu time observed: 1192ms (out of 1236ms)
  Number of samples taken: 23 (once every 52ms)

=================================================
                              Caller
 Idx   Total       Self      Name+src
       ms(pct)     ms(pct)    Callee
=================================================
                              ??? [12]
                              evolve [17]
[17]  818(68.6%)    0(0.0%)  evolve main
                              evolve [17]
                              shuffle-vector [19]
                              death-birth [18]
                              ??? [20]
-------------------------------------------------
                              match-up* [22]
                              shuffle-vector [19]
[24]  152(12.7%)  152(12.7%) contract-wrapper
-------------------------------------------------
    \end{boxedverbatim}
    \caption{Statistical profiler output for the top-right variant} \label{f:fsm-code:statistical}
  \end{subfigure}~\begin{subfigure}[t]{0.44\columnwidth}
    \footnotesize
    \begin{boxedverbatim}
cpu time: 984 real time: 984 gc time: 155
Running time is 18.17% contracts
253/1390 ms

(interface:death-birth pop main)
  142 ms
  (->* ((cons/c (vectorof automaton?)
                (vectorof automaton?))
        any/c)
       (#:random any/c)
       (cons/c (vectorof automaton?)
               (vectorof automaton?)))
(interface:match-up* pop main)
  81.5 ms
  (-> ....)
(interface:population-payoffs pop main)
  29 ms
  (-> ....)


    \end{boxedverbatim}
    \caption{Boundary profiler output for the same variant} \label{f:fsm-code:boundary}
  \end{subfigure}

  \caption{Profiling during type migration} \label{f:fsm-code}
  \Description{Profiling during type migration} 
\end{figure}
%% -----------------------------------------------------------------------------

Still, the idea to continue the migration effort is a good one, because we know
that there are a fair number of well-performing
variants as well as badly-performing ones. The question is how to make progress.

Clearly, informed feedback is needed for a solution that recovers performance
with a reasonable effort. Lacking alternatives, a developer might reach for a
profiling tool to determine the source of the performance
degradation. Fortunately Racket comes with two such tools: 
\begin{itemize}

\item a traditional \emph{statistical profiler}, which identifies the time spent
 in modules; and

\item a \emph{boundary profiler}, which  attributes the cost of types-as-contracts to
 specific module boundaries~\cite{astavf-feature-prf, staaf-feature-prf}.
 
\end{itemize}
Both tools are potentially useful due to the mechanics of deep and shallow types.
In Racket, deep types compile to contracts at module
boundaries~\cite{tf-popl-2008}, so the boundary profiler should identify the
expensive ones.  Shallow types compile to assertions within typed
code~\cite{glfd-pj-2022}, meaning the statistical profiler may uncover their
cost.

The bottom half of \cref{f:fsm-code} shows the output of the statistical
profiler and the boundary profiler for the top-right (deep) variant of \bmname{fsm} in
figure~\ref{f:fsm-code:a}, respectively.

\paragraph{Statistical profiler} \Cref{f:fsm-code:statistical} lists two
rows from the statistical profiler; the full output has 28 rows.  The
first row, labeled \code{[17]}, covers a large percentage (\code{68\%}) of the
total running time, and it refers to a function named \code{evolve}, which is
defined in the \code{main} module. The line suggests that calls from
\code{evolve} to other modules account for a high percentage of the total cost.
The second row, labeled \code{[24]}, says that a contract wrapper accounts for a
significant chunk (\code{12.7\%}) of the running time.  The caller of this
contract, from row \code{[19]} (not shown) is the function \code{shuffle-vector}
from the \code{pop} module.  Putting these clues together, the profiling output
identifies the boundary between \code{main} and \code{pop} as a significant
contributor to the overall cost. 

This conclusion, however, is one of many that could be drawn from the full
statistical profiler output.  The \code{util} module also appears in the output,
and may be more of a performance problem that the \code{pop} module.  Equally
unclear is whether the column labeled \code{Total} is a better guide than
the column labeled \code{Self} or vice versa.  High
total times point to a context that dominates the expensive parts.  High self
times point to expensive parts, but these costs might be from the actual
computation rather than the overhead of type-checking.

\paragraph{Boundary profiler} \Cref{f:fsm-code:boundary} shows nearly-complete
output from the boundary profiler; only two contracts are omitted.  This
profiling output attributes \code{18.17\%} of the total running time to
contracts, specifically, to the contracts on the three functions whose names are
prefixed with \code{interface:}. This output indicates that the contracts are
wrapped on untyped functions that flow into typed code. The modules involved are
\code{main} and \code{pop}.  Since \code{pop} is the untyped one, the hint is to
type it.

Adding types to \code{pop} does improve performance. Concretely, this variant
suffers from a 1.2x slowdown.  If this overhead is acceptable, the developer is
done; otherwise, it might be necessary to continue with another round of
profiling, searching, and typing.


\paragraph{Summary}

At first glance, the effort of eliminating a performance problem seems
straightforward. Several factors complicate the search, however. First, a
programmer has two typing options not just one. Second, for programs with more
than four modules, the output of profiling tools is much more complex;
identifying the next step in such a context is hard. Finally, adding types to the
profiler-identified module may degrade the performance even more, in which case
the programmer may wish to give up. In sum, navigating a migration lattice with
$3^N$ program configuration is a non-trivial effort, and developers deserve to
know how well profiling tools help with this effort. 


