%% -----------------------------------------------------------------------------

Over the years, developers have created many large systems in untyped languages.
In the meantime, language implementors have created gradually typed siblings of
these languages.  Since developers tend to enjoy the benefits of type-based IDE
support and like to type check their code, they are likely to add new components
in the typed sibling language. Alternatively, when a developer is confronted
with debugging an untyped component, it takes a large mental effort to
reconstruct the informal types of its methods, and to make this effort pay off,
it is best to turn the informal types into formal annotations. In either case,
the result is a mixed-typed software system with boundaries between typed and
untyped components. In a sound gradually typed language, these boundaries impose
a performance penalty, possibly a prohibitive one. In the latter case, the
developer faces a performance-debugging scenario.

% \begin{itemize}
%   \item Following the description of the example,  
%     the section should explain how the program evaluates and connect that with the
%     semantics of shallow and deep types. 
%   \item Next, the section should describe the feedback from the statistical
%     profiler, introduce the boundary profiler  and 
%     describe its feedback too. 
%   \item As the feedback of each profiler is shown, the section should 
%     explain that it provides hints about where to look for
%     possible improvements. It would be great, if the section shows how
%     actin on two hints plays out.  
%   \item As a final piece, the section should discuss that the
%     interpretation
%     of the feedback to hints is two dimentional (identify component and
%     identify change to component), and that how a developer can itnerepret
%     it reliably needs a careful and systematic look.
% \end{itemize}

To make this concrete, consider the \bmname{fsm} program from the GTP benchmark
suite~\cite{gtp-benchmarks}. The program is the creation of \citet{fsm},
economist interested in simulating an economy of agents with deterministic
strategies. Figure~\ref{f:fsm-code:a} shows the outline of the four-module
program: \code{auto} implements state machines; \code{pop} coordinates among
machines; \code{main} drives the simulation and permits users to set a number of
simulation parameters; and \code{util} provides helper functions.  Focusing on
just the modules of this program suffices because in Typed Racket, the migration
granularity is a module.

The variant of \bmname{fsm} on the left of figure~\ref{f:fsm-code:a} is untyped.
If a developer adds deep types to the \code{main} module, performance is
significantly degraded. The gradually-typed variant runs almost three times
($3x$) slower than the untyped one.  Switching to shallow types does not remedy
the situation. 

%% 3x not terrible compared to prior work [CITE popl], but still bad.
%% Collapsible helps fsm but not in this particular config & not in fsmoo.

At this point, the question is how to recover the performance of the untyped
variant. The first option is to roll back the addition of types, but developers
prefer typed code and dislike undoing the effort of adding types. The second one
is to add types to a random module connected to \code{main} is one option, but
doing so can easily make things worse. For example, if the choice were the
\code{auto} module with shallow types, then performance would degrade further (a
9x slowdown, to be precise). Finally, adding types to every module is the option
that is almost always guaranteed to fix the situation, and in this context, it
would produce a performance improvement over the untyped variant.  Adding types
to all modules represents a heavy migration effort, however, which a programmer
who started with fixing \code{main} may be reluctant to invest.

%% -----------------------------------------------------------------------------
%% fsm next steps:
%% 1100 => 2.87x
%% 2100 => 9.04x
%% 2200 => 9.06x
%% 1200 => 2.88x

\begin{figure}[htb]\centering
  %% profiler output: data/example-output-fsm/*

  \begin{subfigure}[t]{\columnwidth}\centering
    \begin{tikzpicture}
      \node (1) [draw=black!80] {\code{util}};
      \node (1c) [draw=black!80,left=of 1.west,xshift=9mm] {\code{pop}};
      \node (1b) [draw=black!80,left=of 1c.west,xshift=9mm] {\code{main}};
      \node (1a) [draw=black!80,left=of 1b.west,xshift=9mm] {\code{auto}};
%      \node (0) [above of=1a,yshift=-2mm] {Program: \bmname{fsm}};

      \node (2) [above of=1,yshift=2mm,xshift=3cm,draw=black!80] {\code{auto}};
      \node (2a) [draw=black!80,right=of 2.east,xshift=-9mm] {\code{dp}~\code{main}};
      \node (2b) [draw=black!80,right=of 2a.east,xshift=-9mm] {\code{pop}};
      \node (2c) [draw=black!80,right=of 2b.east,xshift=-9mm] {\code{util}};
      \node (22) [right=of 2c.east,xshift=-10mm] {\textbf{2.9x} slowdown};
%      \node (24) [above of = 22,yshift=-6mm] {Deep types};

      \node (3) [below of=2,yshift=-12mm,draw=black!80] {\code{auto}};
      \node (3a) [draw=black!80,right=of 3.east,xshift=-9mm] {\code{sw}~\code{main}};
      \node (3b) [draw=black!80,right=of 3a.east,xshift=-9mm] {\code{pop}};
      \node (3c) [draw=black!80,right=of 3b.east,xshift=-9mm] {\code{util}};
      \node (33) [right=of 3c.east,xshift=-10mm] {\textbf{2.8x} slowdown};
%      \node (34) [above of = 33,yshift=-6mm] {Shallow types};

      \draw[-{Stealth[length=2mm,width=2mm]}] (1b.north) -- (2a.south);
      \draw[-{Stealth[length=2mm,width=2mm]}] (2a.south) -- (3a.north);

    \end{tikzpicture}

    \caption{Adding deep (dp) or shallow (sw) types to one \bmname{fsm} module degrades performance} \label{f:fsm-code:a}
  \end{subfigure}

  \bigskip

  \begin{subfigure}[t]{0.53\columnwidth}
%%-------------------------------------------------
%% [1] 1192(100.0%)   0(0.0%)  body of ....
%%                              body of ....
%%-------------------------------------------------
%%                              profile-thunk [5]
%% [6] 1192(100.0%)   0(0.0%)  ??? profile-lib
%%                              body of "main" [7]
%%                              t [8]
%%                              body of ....
%%-------------------------------------------------

    \footnotesize
    \begin{boxedverbatim}
  Total cpu time observed: 1192ms (out of 1236ms)
  Number of samples taken: 23 (once every 52ms)

=================================================
                              Caller
 Idx   Total       Self      Name+src
       ms(pct)     ms(pct)    Callee
=================================================
                              ??? [12]
                              evolve [17]
[17]  818(68.6%)    0(0.0%)  evolve main
                              evolve [17]
                              shuffle-vector [19]
                              death-birth [18]
                              ??? [20]
-------------------------------------------------
                              match-up* [22]
                              shuffle-vector [19]
[24]  152(12.7%)  152(12.7%) contract-wrapper
-------------------------------------------------
    \end{boxedverbatim}
    \caption{Statistical profiler output for deep types} \label{f:fsm-code:statistical}
  \end{subfigure}~\begin{subfigure}[t]{0.44\columnwidth}
    \footnotesize
    \begin{boxedverbatim}
cpu time: 984 real time: 984 gc time: 155
Running time is 18.17% contracts
253/1390 ms

(interface:death-birth pop main)
  142 ms
  (->* ((cons/c (vectorof automaton?)
                (vectorof automaton?))
        any/c)
       (#:random any/c)
       (cons/c (vectorof automaton?)
               (vectorof automaton?)))
(interface:match-up* pop main)
  81.5 ms
  (-> ....)
(interface:population-payoffs pop main)
  29 ms
  (-> ....)


    \end{boxedverbatim}
    \caption{Boundary profiler output for deep types} \label{f:fsm-code:boundary}
  \end{subfigure}

  \caption{Profiling during gradual-type migration} \label{f:fsm-code}
\end{figure}
%% -----------------------------------------------------------------------------

Still, the idea to continue the migration effort is a good one, because we know
that many of the corresponding lattices contain a fair number of well-performing
variants as well as badly-performing ones. The question is how to make progress.

Clearly, informed feedback is needed for a solution that recovers performance
with a reasonable effort. Lacking alternatives, a developer might reach for a
profiling tool to determine the source of the performance
degradation. Fortunately Racket comes with two such tools: 
\begin{itemize}

\item a traditional \emph{statistical profiler}, which identifies the time spent
 in modules; and

\item a \emph{boundary profiler}, which attributes the cost of contracts to
 module boundaries.
 
\end{itemize}
Both tools are potentially useful due to the mechanics of deep and shallow types.
Deep types compile to contracts at module boundaries~\cite{tf-popl-2008}, so
the boundary profiler should identify them expensive ones. 
Shallow types compile to assertions within typed code~\cite{glfd-pj-2022},
meaning the statistical profiler may uncover this additional and suggest
toggling the module to deep types. 

The bottom half of \cref{f:fsm-code} shows the output of the statistical
profiler and the boundary profiler for the top-right variant of \bmname{fsm} in
figure~\ref{f:fsm-code:a}, respectively.

\paragraph{Statistical profiler} \Cref{f:fsm-code:statistical} lists two the
first two rows from the statistical profiler; the full output has 28 rows.  The
first row, labeled \code{[17]}, covers a large percentage (\code{68\%}) of the
total running time, and it refers to a function named \code{evolve}, which is
defined in the \code{main} module. The line suggests that calls from
\code{evolve} to other modules account for a high percentage of the total cost.
The second row, labeled \code{[24]}, says that a contract wrapper accounts for a
significant chunk (\code{12.7\%}) of the running time.  The caller of this
contract, from row \code{[19]} (not shown) is the function \code{shuffle-vector}
from the \code{pop} module.  Putting these clues together, the profiling output
identifies the boundary between \code{main} and \code{pop} as a significant
contributor to the overall cost. 

This conclusion, however, is one of many that could be drawn from the full
statistical profiler output.  The \code{util} module also appears in the output,
and may be more of a bottleneck that the \code{pop} module.  Equally unclear is
whether the time the column labeled \code{Total} is a better guide than the
percentages listed in the column labeled \code{Self} or vice versa.  High total
times point to a context that dominates the expensive parts.  High self times
point to expensive parts, but these costs might be from the actual computation
rather than the type-checking.

\paragraph{Boundary profiler} \Cref{f:fsm-code:boundary} shows nearly-complete
output from the boundary profiler; only two contracts are omitted.  This
profiling output attributes \code{18.17\%} of the total running time to
contracts, specifically, to the contracts on the three functions whose names are
prefixed with \code{interface:}. This output indicates that the contracts are
wrapped on untyped functions that flow into typed code. The modules involved are
\code{main} and \code{pop}.  Since \code{pop} is the untyped one, the hint is to
type it.

Adding types to \code{pop} does improve performance. Concretely, this variant
suffers from a 1.2x slowdown.  If this overhead is acceptable, the developer is
done; otherwise, it might be necessary to continue with another round of
profiling, searching, and typing.

\medskip

At first glance, the effort of eliminating a performance bottleneck seems
straightforward. Several factors complicate the search, however. First, a
programmer has two typing options not just one. Second, for programs with more
than four modules, the output of profiling tools is much more complex;
identifying the next step in this context is hard. Finally, adding types to the
profiler-identified module may degrade the performance even more, in which case
the programmer may wish to give up. In sum, navigating a migration lattice with
$3^N$ program configuration is a non-trivial effort, and developers deserve to
know how well profiling tools help with this effort. 


