%% -----------------------------------------------------------------------------

Over the years, developers have created many large systems in untyped languages.
In the meantime, language implementors have created gradually typed siblings of
these languages.  Since developers tend to enjoy the benefits of type-based IDE
support and a blessing from the type checker, they are likely to add new
components in the typed sibling language. Alternatively, when a developer must
debug an untyped component, it takes a large mental effort
to reconstruct the informal types of fields, functions, and methods, and to make
this effort pay off, it is best to turn the informal types into formal
annotations. In either case, the result is a mixed-typed software system with
boundaries between typed and untyped components.

In a sound gradual language, these boundaries impose a performance penalty.
Languages can enforce sound types without limiting
expressiveness\footnote{Nom~\cite{mt-oopsla-2017} and Static
Python~\cite{lgmvpk-pj-2023} have low-cost but restrictive soundness
checks.} in several ways~\cite{type-untyped}.
The leading approaches are deep and shallow checks:
\begin{itemize}
  \item
    Deep checks enforce types by translating them to higher-order
    contracts at the boundaries to untyped code~\cite{ff-icfp-2002,tf-dls-2006,st-sfp-2006}.
    Higher-order contracts impose many kinds of performance penalties: they
    traverse compound values; they wrap higher-order values with proxies
    to delay checks; and they raise memory consumption via the proxies.
    If there are few boundaries, however, then deep checks impose few costs
    and type-driven optimizations may exceed the performance of untyped code~\cite{gtnffvf-jfp-2019}.

  \item
    Shallow checks enforce types with tag-level
    assertions that ask simple questions (is this a list?)
    and never allocate proxies~\cite{vss-popl-2017, vksb-dls-2014}.
    Each check is inexpensive, but the lack of proxies blurs the lines between
    typed and untyped code and leads to a conservatively high number of checks.
    Suppose a typed function expects a callback.
    If the callback might be supplied by untyped code, then every call needs
    a check around it to ensure soundness---even if most calls are safe.
    In general, more shallow types lead to more checks.

\end{itemize}
In either case, the performance penalty can become too high.
If so, the developer faces a performance-debugging scenario.

To make these ideas concrete, consider the \bmname{fsm} program from the GTP benchmark
suite~\cite{gtnffvf-jfp-2019,g-rep-2023}. The program is the creation of \citet{fsm},
economists interested in simulating an economy of agents with deterministic
strategies. \Cref{f:fsm-code:a} shows the outline of the four-module
program: \code{auto} implements state machines; \code{pop} coordinates among
machines; \code{main} drives the simulation;
%% and permits users to set a number of simulation parameters
and \code{util} provides helper functions.  Focusing on
just the modules of this program suffices because the migration granularity
in Typed Racket is by module (each module can be typed or untyped).

%% -----------------------------------------------------------------------------
%% fsm next steps:
%% 1100 => 2.87x
%% 2100 => 9.04x
%% 2200 => 9.06x
%% 1200 => 2.88x

\begin{figure}[htb]\centering
  %% profiler output: data/example-output-fsm/*

  \begin{subfigure}[t]{\columnwidth}\centering
    \begin{tikzpicture}
      \node (1) [draw=black!80] {\cmod{util}};
      \node (1c) [draw=black!80,left=of 1.west,xshift=9mm] {\cmod{pop}};
      \node (1b) [draw=black!80,left=of 1c.west,xshift=9mm] {\cmod{main}};
      \node (1a) [draw=black!80,left=of 1b.west,xshift=9mm] {\cmod{auto}};
%      \node (0) [above of=1a,yshift=-2mm] {Program: \bmname{fsm}};

      \node (2) [above of=1,yshift=1mm,xshift=2cm,draw=black!80] {\cmod{auto}};
      \node (2a) [draw=black!80,line width=0.6mm,right=of 2.east,xshift=-9mm] {\cmod{main}};
      \node (2tgt) [below of=2a,yshift=7mm,xshift=1mm] {};
      \node (2b) [draw=black!80,right=of 2a.east,xshift=-9mm] {\cmod{pop}};
      \node (2c) [draw=black!80,right=of 2b.east,xshift=-9mm] {\cmod{util}};
      \node (22) [right=of 2c.east,xshift=-10mm] {\textbf{2.9x} slowdown};
%      \node (24) [above of = 22,yshift=-6mm] {Deep types};

      \node (3) [below of=2,yshift=-6mm,draw=black!80] {\cmod{auto}};
      \node (3a) [draw=black!80,line width=0.6mm,right=of 3.east,xshift=-9mm] {\cmod{main}};
      \node (3b) [draw=black!80,right=of 3a.east,xshift=-9mm] {\cmod{pop}};
      \node (3c) [draw=black!80,right=of 3b.east,xshift=-9mm] {\cmod{util}};
      \node (33) [right=of 3c.east,xshift=-10mm] {\textbf{2.8x} slowdown};
%      \node (34) [above of = 33,yshift=-6mm] {Shallow types};

      \node (dlbl) [above of=2a,yshift=-5mm] {deep};
      \node (slbl) [below of=3a,yshift=5mm] {shallow};

      \draw[-{Stealth[length=2mm,width=2mm]}] (1b.north) -- (2tgt);
      \draw[-{Stealth[length=2mm,width=2mm]}] (2a.south) -- (3a.north);

    \end{tikzpicture}

    \caption{Adding deep or shallow types to one \bmname{fsm} module degrades performance} \label{f:fsm-code:a}
  \end{subfigure}

  \bigskip

  \begin{subfigure}[t]{0.53\columnwidth}
%%-------------------------------------------------
%% [1] 1192(100.0%)   0(0.0%)  body of ....
%%                              body of ....
%%-------------------------------------------------
%%                              profile-thunk [5]
%% [6] 1192(100.0%)   0(0.0%)  ??? profile-lib
%%                              body of "main" [7]
%%                              t [8]
%%                              body of ....
%%-------------------------------------------------

    \footnotesize
    \begin{boxedverbatim}
  Total cpu time observed: 1192ms (out of 1236ms)
  Number of samples taken: 23 (once every 52ms)

=================================================
                              Caller
 Idx   Total       Self      Name+src
       ms(pct)     ms(pct)    Callee
=================================================
                              ??? [12]
                              evolve [17]
[17]  818(68.6%)    0(0.0%)  evolve main
                              evolve [17]
                              shuffle-vector [19]
                              death-birth [18]
                              ??? [20]
-------------------------------------------------
                              match-up* [22]
                              shuffle-vector [19]
[24]  152(12.7%)  152(12.7%) contract-wrapper
-------------------------------------------------
    \end{boxedverbatim}
    \caption{Statistical profiler output for the top-right variant} \label{f:fsm-code:statistical}
  \end{subfigure}~\begin{subfigure}[t]{0.44\columnwidth}
    \footnotesize
    \begin{boxedverbatim}
cpu time: 984 real time: 984 gc time: 155
Running time is 18.17% contracts
253/1390 ms

(interface:death-birth pop main)
  142 ms
  (->* ((cons/c (vectorof automaton?)
                (vectorof automaton?))
        any/c)
       (#:random any/c)
       (cons/c (vectorof automaton?)
               (vectorof automaton?)))
(interface:match-up* pop main)
  81.5 ms
  (-> ....)
(interface:population-payoffs pop main)
  29 ms
  (-> ....)


    \end{boxedverbatim}
    \caption{Boundary profiler output for the same variant} \label{f:fsm-code:boundary}
  \end{subfigure}

  \caption{Profiling during type migration} \label{f:fsm-code}
  \Description{Profiling during type migration} 
\end{figure}
%% -----------------------------------------------------------------------------

The variant of \bmname{fsm} on the left of figure~\ref{f:fsm-code:a} is untyped.
If a developer adds deep types to the \code{main} module, performance is
significantly degraded. The mixed-typed variant runs almost three times
($3x$) slower than the untyped one.  Switching to shallow types is a one-line
change to the module language, but does not remedy the situation.
At this point, the question is how to recover the performance of the untyped
variant:
\begin{itemize} \item[] \begin{itemize}
  \item
One option is to roll back the addition of types.
  \item
For developers who prefer typed code and dislike undoing the effort of
adding types, a second option is to add
(deep or shallow) types to a random module connected to \code{main}---following a
``hunch'' like programmers sometimes do---but doing so can easily make things
worse. For example, if the choice were the \code{auto} module with shallow
types, then performance would degrade further (a 9x slowdown, to be
precise).
  \item
If the developer adds deep types to every module, then \bmname{fsm}
has no type boundaries and gets the full benefit of optimizations. Performance
improves over the untyped variant.
However, such a choice
represents a heavy migration effort, which a programmer who simply
wishes to fix \code{main} and deploy again may be reluctant to invest.
\end{itemize} \end{itemize}
None of these options are compelling.
Informed feedback is clearly needed for a solution that recovers performance
with a reasonable effort and without discarding types.

The natural choice is to reach for a
profiling tool to determine the source of the slowdown.
Racket fortunately comes with two such tools: 
\begin{itemize} \item[] \begin{itemize}

\item a traditional \emph{statistical profiler}, which identifies the time spent
 in modules; and

\item a \emph{boundary profiler}, which  attributes the cost of types-as-contracts to
 specific module boundaries~\cite{astavf-feature-prf, staaf-feature-prf}.

\end{itemize} \end{itemize}
Both tools are potentially useful and potentially limited due to the mechanics
of deep and shallow types.
In Racket, deep types compile to contracts at module
boundaries~\cite{tf-popl-2008}, so the boundary profiler should identify the
expensive ones.  Shallow types compile to assertions within typed
code~\cite{glfd-pj-2022}, meaning the statistical profiler may uncover their
cost.
Take, for example, a function that averages a list of numbers:

\begin{verbatim}
  (: avg (-> [Listof Real] Real))         ;; deep: enforce type as a contract
  (define (avg l) (/ (sum l) (length l))) ;; shallow: rewrite code with checks
\end{verbatim}

\begin{itemize}
  \item
    With deep checks, the function gets wrapped in a proxy, which is
    derived from the type, before it crosses over to untyped code.
    The proxy checks that untyped calls
    fully match the type by traversing input lists.
    The \emph{boundary profiler} is well-suited to discover if these
    checks are expensive because it attributes costs directly to proxies.
    By contrast, the statistical profiler would seem less likely to
    succeed because it attributes costs to modules; however, it may
    indirectly discover expensive proxies if they slow down an enclosing
    module.
  \item
    With shallow checks, the compiler bakes in a test for
    \code{list?}, which does not traverse the list.
    If the helper function \code{sum} is typed, then it also has checks
    that validate list elements.
    Because there are no contracts in the shallow version, only checks, the
    boundary profiler cannot measure the cost of the types.
    The \emph{statistical profiler} is in a much better position to find
    costs because they arise from extra code in each function.
\end{itemize}

Back to \bmname{fsm}, the bottom half of \cref{f:fsm-code} shows the output of the statistical
profiler and the boundary profiler for the top-right (deep) variant in
figure~\ref{f:fsm-code:a}.

\paragraph{Statistical profiler} \Cref{f:fsm-code:statistical} lists two
rows from the statistical profiler; the full output has 28 rows.  The
first row, labeled \code{[17]}, covers a large percentage (\code{68\%}) of the
total running time, and it refers to a function named \code{evolve}, which is
defined in the \code{main} module. The line suggests that calls from
\code{evolve} to other modules account for a high percentage of the total cost.
The second row, labeled \code{[24]}, says that a contract wrapper accounts for a
significant chunk (\code{12.7\%}) of the running time.  The caller of this
contract, from row \code{[19]} (not shown) is the function \code{shuffle-vector}
from the \code{pop} module.  Putting these clues together, the profiling output
identifies the boundary between \code{main} and \code{pop} as a significant
contributor to the overall cost. 

This conclusion, however, is one of many that could be drawn from the full
statistical profiler output.  The \code{util} module also appears in the output,
and may be more of a performance problem that the \code{pop} module.  Equally
unclear is whether the column labeled \code{Total} is a better guide than
the column labeled \code{Self} or vice versa.  High
total times point to a context that dominates the expensive parts.  High self
times point to expensive parts, but these costs might be from the actual
computation rather than the overhead of type-checking.

\paragraph{Boundary profiler} \Cref{f:fsm-code:boundary} shows nearly-complete
output from the boundary profiler; only two contracts are omitted.  This
profiling output attributes \code{18.17\%} of the total running time to
contracts, specifically, to the contracts on the three functions whose names
begin with an \code{interface:} prefix.
This output indicates that the contracts are
wrapped on untyped functions that flow into typed code. The modules involved are
\code{main} and \code{pop}.  Since \code{pop} is the untyped one, the hint is to
type it.

Adding types to \code{pop} does improve performance. Concretely, this variant
suffers from a 1.2x slowdown.  If this overhead is acceptable, the developer is
done; otherwise, the search must continue with another round of
profiling, searching, and typing.


\paragraph{Summary}

At first glance, the effort of eliminating a performance problem seems
straightforward. Several factors complicate the search. First, a
programmer has two typing options not just one. Second, the output from
profiling tools is complex. Even for this small program, the statistical
profiler outputs 100 lines;
identifying the next step is hard. Finally, adding types to the
profiler-identified module may degrade the performance even more, in which case
the programmer may wish to give up. In sum:

\begin{quote} \em
Navigating a migration lattice with
$3^N$ program configuration is a non-trivial effort, and developers deserve to
know how well profiling tools help with this effort.
\end{quote}

