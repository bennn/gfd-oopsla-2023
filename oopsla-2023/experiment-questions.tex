%% -----------------------------------------------------------------------------

Equipped with rigorous definitions, it is possible to formulate the research
questions precisely:
\begin{description}

\item[$Q_X$] How successful is a strategy $X$ with the elimination of
  performance overhead?

\item[$Q_{X/Y}$] Is strategy $X$ more successful than strategy $Y$ in this
  context?

\end{description}

Answering $Q_X$ boils down to determining the success and failures of
$X$ for all performance-debugging
scenarios in all available lattices. If, for a large number of scenarios,
$X$ charts migration paths that are strictly successful, the answer is
positive. Essentially, the large number of scenarios is evidence that when a
rational programmer reacts to profiler feedback following $X$, it is likely to
improve performance. Notably, the above
description uses the strict notion of success, which sets a high bar.
Hence, the rational programmer not only manages to tune performance at
a tolerable level but each suggestion of its strategy brings the rational
programmer closer to its target. Swapping the notion of strict success for
$k$-loose success relaxes this high standard, and offers answers to $Q_X$ when
allowing for some bounded flexibility in how well the intermediate suggestions
of $X$ help the rational programmer. For completeness, the next section also
reports the data collected for the notion of $N$-loose success.

While an answer to $Q_X$ constitutes an evaluation of a strategy $X$ for
interpreting profiler feedback in absolute terms, an answer to $Q_{X/Y}$ is
about the relative value of $X$ versus some other strategy
$Y$. This second question asks whether the proportion of scenarios
in which $X$ succeeds and $Y$ fails is higher that
the proportion of scenarios where $Y$ succeeds and
$X$ fails. Of course, the answer may not be clear cut as $X$ and $Y$
may perform equally well in most scenarios, or may have complementary success
records. But, relaxing the notion of success by different factors $k$ may
help distinguish $X$ and $Y$ based on the quality of the feedback they produce.

Importantly, when $Y$ is the $\randkw{}$ strategy and the answer to
$Q_X/\randkw$ is positive, then the experiment invalidates its null-hypothesis.
Put differently, the success of $X$ is not due to sheer luck but the rational
use of profiler feedback.

Summing up, the rational programmer process for answering $Q_X$ and $Q_{X/Y}$ rests on the following
experimental plan:
\begin{enumerate}

\item Create a large and diverse corpus of performance-debugging scenarios.

\item Calculate the migration paths for each strategy for
  each scenario.

\item Compare the successes and failures of the strategies.

\end{enumerate}

\paragraph{Isn't Gradual Typing Dead?}
Although prior work shows that many configurations of the GTP benchmarks
run slowly, it does not answer the $Q_X$ and $Q_{X/Y}$ questions---even
in the $N$-loose case.  \citet{gtnffvf-jfp-2019} attempt to
investigate an $N$-loose version of  $Q_X$ in a $2^N$ lattice, but severely limit the length of paths.
\citet{g-deep-shallow} consider longer paths, but only those that start from the untyped
configuration and end at a fully-typed configuration.
Neither study tests whether
configurations that have high slowdown can be systematically
transformed to ones with acceptable performance (say: $80x \rightarrow 70x
\rightarrow 20x \rightarrow 1x$). That said, without the rational programmer 
method it is by no means clear how to examine such questions in a
principled manner.
